{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bT0to3TL2q7H"
   },
   "source": [
    "# Ungraded Lab: Transfer Learning\n",
    "\n",
    "In this lab, you will see how you can use a pre-trained model to achieve good results even with a small training dataset. This is called _transfer learning_ and you do this by leveraging the trained layers of an existing model and adding your own layers to fit your application. For example, you can:\n",
    "\n",
    "1. just get the convolution layers of one model\n",
    "2. attach some dense layers onto it\n",
    "3. train just the dense network\n",
    "4. evaluate the results\n",
    "\n",
    "Doing this will allow you to save time building your application because you will essentially skip weeks of training time of very deep networks. You will just use the features it has learned and tweak it for your dataset. Let's see how these are done in the next sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-12slkPL6_JH"
   },
   "source": [
    "## Setup the pretrained model\n",
    "\n",
    "You will need to prepare the pretrained model and configure the layers that you need. For this exercise, you will use the convolution layers of the [InceptionV3](https://arxiv.org/abs/1512.00567) architecture as your base model. To do that, you need to:\n",
    "\n",
    "1. Set the input shape to fit your application. In this case. set it to `150x150x3` as you've been doing in the last few labs.\n",
    "\n",
    "2. Pick and freeze the convolution layers to take advantage of the features it has learned already.\n",
    "\n",
    "3. Add dense layers which you will train.\n",
    "\n",
    "Let's see how to do these in the next cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VqhFEK2Y-PK"
   },
   "source": [
    "First, in preparing the input to the model, you want to fetch the pretrained weights of the `InceptionV3` model and remove the fully connected layer at the end because you will be replacing it later. You will also specify the input shape that your model will accept. Lastly, you want to freeze the weights of these layers because they have been trained already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [],
   "source": [
    "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
    "# The weights have been pre-downloaded for you from the following URL:\n",
    "# https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KsiBCpQ1VvPp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the weights file you downloaded into a variable\n",
    "local_weights_file = 'model/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# Initialize the base model.\n",
    "# Set the input shape and remove the dense layers.\n",
    "pre_trained_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    input_shape = (150, 150, 3),\n",
    "    include_top = False,\n",
    "    weights = None)\n",
    "\n",
    "# Load the pre-trained weights you downloaded.\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Freeze the weights of the layers.\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "['/device:CPU:0', '/device:GPU:0']\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())\n",
    "# It should be ['/device:CPU:0', '/device:GPU:0']\n",
    "\n",
    "#usar GPU\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1y2rEnqFaa9k"
   },
   "source": [
    "You can see the summary of the model below. You can see that it is a very deep network. You can then select up to which point of the network you want to use. As Laurence showed in the exercise, you will use up to `mixed7` as your base model and add to that. This is because the original last layer might be too specialized in what it has learned so it might not translate well into your application. `mixed7` on the other hand will be more generalized and you can start with that for your application. After the exercise, feel free to modify and use other layers to see what the results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qeGP0Ust5kCR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 7, 7, 192)   576         ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 7, 7, 192)   576         ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 7, 7, 192)   576         ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 7, 7, 192)   576         ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 3, 3, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 3, 3, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 3, 3, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 3, 3, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 3, 3, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 3, 3, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 3, 3, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3, 3, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 3, 3, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 3, 3, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 3, 3, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 3, 3, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jDmGO9tg5iPc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 192)\n"
     ]
    }
   ],
   "source": [
    "# Choose `mixed7` as the last layer of your base model\n",
    "last_layer = pre_trained_model.get_layer('batch_normalization_73')\n",
    "print('last layer output shape: ', last_layer.output.shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXT9SDMK7Ioa"
   },
   "source": [
    "## Add dense layers for your classifier\n",
    "\n",
    "Next, you will add dense layers to your model. These will be the layers that you will train and is tasked with recognizing cats and dogs. You will add a [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer as well to regularize the output and avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BMXb913pbvFg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 7, 7, 192)   576         ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 7, 7, 192)   576         ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 9408)         0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         9634816     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1024)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            1025        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 19,017,761\n",
      "Trainable params: 9,635,841\n",
      "Non-trainable params: 9,381,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = tf.keras.layers.Flatten()(last_output)\n",
    "\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# Add a final sigmoid layer for classification\n",
    "x = tf.keras.layers.Dense  (1, activation='sigmoid')(x)\n",
    "\n",
    "# Append the dense network to the base model\n",
    "model = tf.keras.Model(pre_trained_model.input, x)\n",
    "\n",
    "# Print the model summary. See your dense network connected at the end.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYLGw_RO7Z_X"
   },
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "Now you will prepare the dataset. This is basically the same code as the one you used in the data augmentation lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WOV8jON3c3Jv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3435 files belonging to 2 classes.\n",
      "Found 85 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = 'D:/ifons/Documents/Tensorflow/tensorflow-1-public-main/C2/W2/ungraded_labs/data'\n",
    "\n",
    "train_dir = os.path.join(BASE_DIR, 'train')\n",
    "validation_dir = os.path.join(BASE_DIR, 'test1')\n",
    "\n",
    "# Directory with training cat/dog pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with validation cat/dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Prepare the training set\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    label_mode='binary'\n",
    "    )\n",
    "\n",
    "# Prepare the validation set\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    label_mode='binary'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using pretrained models, you should make it a habit to check the documentation for any preprocessing steps. In this case, the [InceptionV3 documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/InceptionV3) says that the inputs should be scaled to the range [-1,1]. It has a [`preprocess_input()`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input)  method that you can use to rescale the inputs. The cell below defines a `preprocess` function that uses this method, which you can then map to the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocess function\n",
    "def preprocess(image, label):\n",
    "    image = tf.keras.applications.inception_v3.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Apply the preprocessing to the datasets\n",
    "train_dataset_scaled = train_dataset.map(preprocess)\n",
    "validation_dataset_scaled = validation_dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the datasets for training\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset_final = (train_dataset_scaled\n",
    "                       .cache()\n",
    "                       .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                       .prefetch(PREFETCH_BUFFER_SIZE)\n",
    "                       )\n",
    "\n",
    "validation_dataset_final = (validation_dataset_scaled\n",
    "                            .cache()\n",
    "                            .prefetch(PREFETCH_BUFFER_SIZE)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJ2I1nk398e5"
   },
   "source": [
    "## Prepare the Model for Training\n",
    "\n",
    "You will also add data augmentation layers to avoid your model from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6UnVzMxijYWu"
   },
   "outputs": [],
   "source": [
    "# Create a model with data augmentation layers\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.4),\n",
    "    tf.keras.layers.RandomTranslation(0.2,0.2),\n",
    "    tf.keras.layers.RandomContrast(0.4),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uCGopMv-m3Zb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 1)                 19017761  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,017,761\n",
      "Trainable params: 9,635,841\n",
      "Non-trainable params: 9,381,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Attach the data augmentation model to the base model\n",
    "inputs = tf.keras.Input(shape=(150, 150, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = model(x)\n",
    "\n",
    "model_with_aug = tf.keras.Model(inputs, x)\n",
    "model_with_aug.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGf3b-fK-tOl"
   },
   "source": [
    "Finally, you will compile the model with the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A9ofMGh5kXMW"
   },
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "model_with_aug.compile(\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m3S6AZb7h-B"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "With that, you can now train the model. You will do 20 epochs and plot the results afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "172/172 - 99s - loss: 0.7800 - accuracy: 0.6207 - val_loss: 0.2125 - val_accuracy: 0.9412 - 99s/epoch - 577ms/step\n",
      "Epoch 2/20\n",
      "172/172 - 46s - loss: 0.6624 - accuracy: 0.6629 - val_loss: 0.1586 - val_accuracy: 0.9647 - 46s/epoch - 267ms/step\n",
      "Epoch 3/20\n",
      "172/172 - 46s - loss: 0.6347 - accuracy: 0.6687 - val_loss: 0.1570 - val_accuracy: 0.9412 - 46s/epoch - 270ms/step\n",
      "Epoch 4/20\n",
      "172/172 - 46s - loss: 0.5905 - accuracy: 0.6865 - val_loss: 0.2133 - val_accuracy: 0.9294 - 46s/epoch - 268ms/step\n",
      "Epoch 5/20\n",
      "172/172 - 46s - loss: 0.5833 - accuracy: 0.6897 - val_loss: 0.1292 - val_accuracy: 0.9647 - 46s/epoch - 267ms/step\n",
      "Epoch 6/20\n",
      "172/172 - 46s - loss: 0.5645 - accuracy: 0.6940 - val_loss: 0.1955 - val_accuracy: 0.9294 - 46s/epoch - 267ms/step\n",
      "Epoch 7/20\n",
      "172/172 - 46s - loss: 0.5595 - accuracy: 0.7089 - val_loss: 0.1211 - val_accuracy: 0.9647 - 46s/epoch - 269ms/step\n",
      "Epoch 8/20\n",
      "172/172 - 45s - loss: 0.5678 - accuracy: 0.6996 - val_loss: 0.1494 - val_accuracy: 0.9647 - 45s/epoch - 264ms/step\n",
      "Epoch 9/20\n",
      "172/172 - 47s - loss: 0.5644 - accuracy: 0.6972 - val_loss: 0.1479 - val_accuracy: 0.9529 - 47s/epoch - 274ms/step\n",
      "Epoch 10/20\n",
      "172/172 - 47s - loss: 0.5619 - accuracy: 0.6943 - val_loss: 0.1760 - val_accuracy: 0.9529 - 47s/epoch - 273ms/step\n",
      "Epoch 11/20\n",
      "172/172 - 47s - loss: 0.5520 - accuracy: 0.7130 - val_loss: 0.1685 - val_accuracy: 0.9294 - 47s/epoch - 272ms/step\n",
      "Epoch 12/20\n",
      "172/172 - 45s - loss: 0.5549 - accuracy: 0.7115 - val_loss: 0.1477 - val_accuracy: 0.9647 - 45s/epoch - 263ms/step\n",
      "Epoch 13/20\n",
      "172/172 - 46s - loss: 0.5475 - accuracy: 0.7095 - val_loss: 0.1436 - val_accuracy: 0.9647 - 46s/epoch - 270ms/step\n",
      "Epoch 14/20\n",
      "172/172 - 43s - loss: 0.5503 - accuracy: 0.7124 - val_loss: 0.1457 - val_accuracy: 0.9647 - 43s/epoch - 249ms/step\n",
      "Epoch 15/20\n",
      "172/172 - 44s - loss: 0.5446 - accuracy: 0.7086 - val_loss: 0.1387 - val_accuracy: 0.9647 - 44s/epoch - 256ms/step\n",
      "Epoch 16/20\n",
      "172/172 - 43s - loss: 0.5414 - accuracy: 0.7167 - val_loss: 0.1525 - val_accuracy: 0.9529 - 43s/epoch - 250ms/step\n",
      "Epoch 17/20\n",
      "172/172 - 43s - loss: 0.5362 - accuracy: 0.7205 - val_loss: 0.1834 - val_accuracy: 0.9647 - 43s/epoch - 252ms/step\n",
      "Epoch 18/20\n",
      "172/172 - 45s - loss: 0.5401 - accuracy: 0.7051 - val_loss: 0.2382 - val_accuracy: 0.9412 - 45s/epoch - 259ms/step\n",
      "Epoch 19/20\n",
      "172/172 - 44s - loss: 0.5381 - accuracy: 0.7170 - val_loss: 0.1308 - val_accuracy: 0.9647 - 44s/epoch - 253ms/step\n",
      "Epoch 20/20\n",
      "172/172 - 45s - loss: 0.5254 - accuracy: 0.7226 - val_loss: 0.1283 - val_accuracy: 0.9765 - 45s/epoch - 260ms/step\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# Train the model.\n",
    "history = model_with_aug.fit(\n",
    "    train_dataset_final,\n",
    "    validation_data = validation_dataset_final,\n",
    "    epochs = EPOCHS,\n",
    "    verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwcB2bPj7lIx"
   },
   "source": [
    "## Evaluate the results\n",
    "\n",
    "You will use the same code to plot the results. As you can see, the validation accuracy is steady at around 95% even as your training accuracy improves. This is a good sign that your model is not overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/IAAAIjCAYAAACgdyAGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAADBCUlEQVR4nOzdeVxU1fsH8M8wyCYCKgioJIr7hoXJzwW1wnCJ3DJcUXL5Zu6kKblrSYsapiblV9QsjVIyyyWVtNwpzS1xR1ECFE1QTNDh/v443xkcGZDlztwZ+Lxfr3kxc+beO88d0JnnnnOeo5IkSQIRERERERERWQQrpQMgIiIiIiIiouJjIk9ERERERERkQZjIExEREREREVkQJvJEREREREREFoSJPBEREREREZEFYSJPREREREREZEGYyBMRERERERFZECbyRERERERERBaEiTwRERERERGRBWEiTxZn2LBh8Pb2LtW+c+bMgUqlkjcgM3PlyhWoVCqsWbPGpK+7d+9eqFQq7N27V9dW3N+VsWL29vbGsGHDZD0mERFZLn6HKBq/Q+RT6jvEmjVroFKpcOXKFZO/NlkWJvIkG5VKVazb4/9JE5XVwYMHMWfOHNy5c0fpUIiIqJT4HYKUwO8QZMmslQ6Ayo9169bpPf7yyy+xa9euAu1NmjQp0+usXLkSeXl5pdp3xowZmDZtWplen4qvLL+r4jp48CDmzp2LYcOGwcXFRe+5c+fOwcqK1yuJiMwdv0PQk/gdgqhoTORJNoMHD9Z7fPjwYezatatA+5Pu378PBweHYr9OpUqVShUfAFhbW8Pamn/2plKW35UcbG1tFX19S5GdnY3KlSsrHQYRVWD8DkFP4ncIoqLxMhOZVOfOndG8eXMcPXoUHTt2hIODA959910AwA8//IAePXqgZs2asLW1hY+PD+bPnw+NRqN3jCfnTGnnRi1cuBBffPEFfHx8YGtri+effx6///673r6G5repVCqMHTsWmzdvRvPmzWFra4tmzZphx44dBeLfu3cvWrduDTs7O/j4+ODzzz8v9py5ffv2oV+/fnjmmWdga2sLLy8vTJo0Cf/++2+B83N0dERKSgp69eoFR0dHuLm5YfLkyQXeizt37mDYsGFwdnaGi4sLhg4dWqzhYX/88QdUKhXWrl1b4Lmff/4ZKpUKP/30EwDg6tWreOutt9CoUSPY29ujevXq6NevX7Hmbhma31bcmE+ePIlhw4ahXr16sLOzg4eHB9544w3cunVLt82cOXMwZcoUAEDdunV1Qy+1sRma33b58mX069cP1apVg4ODA/7v//4PW7du1dtGO1fv22+/xfvvv4/atWvDzs4OL730Ei5evPjU8y7Je3bnzh1MmjQJ3t7esLW1Re3atREaGoqMjAzdNg8ePMCcOXPQsGFD2NnZwdPTE3369MGlS5f04n1yyKmheYPav69Lly6he/fuqFKlCgYNGgSg+H+jAHD27Fm8/vrrcHNzg729PRo1aoTp06cDAPbs2QOVSoXvv/++wH7r16+HSqXCoUOHnvo+EhE9jt8h+B2iInyHKMxnn32GZs2awdbWFjVr1sSYMWMKnPuFCxfQt29feHh4wM7ODrVr10b//v2RmZmp22bXrl3o0KEDXFxc4OjoiEaNGun+HZFl4WVFMrlbt26hW7du6N+/PwYPHgx3d3cAoriHo6MjwsPD4ejoiF9++QWzZs1CVlYWPv7446ced/369bh79y7+85//QKVS4aOPPkKfPn1w+fLlp17V3b9/P+Li4vDWW2+hSpUq+PTTT9G3b18kJyejevXqAIA///wTXbt2haenJ+bOnQuNRoN58+bBzc2tWOf93Xff4f79+xg9ejSqV6+OhIQELF26FNevX8d3332nt61Go0FQUBD8/f2xcOFC7N69G4sWLYKPjw9Gjx4NAJAkCT179sT+/fvx5ptvokmTJvj+++8xdOjQp8bSunVr1KtXD99++22B7WNjY1G1alUEBQUBAH7//XccPHgQ/fv3R+3atXHlyhWsWLECnTt3xpkzZ0rUE1KSmHft2oXLly8jLCwMHh4e+Ouvv/DFF1/gr7/+wuHDh6FSqdCnTx+cP38eGzZswCeffAJXV1cAKPR3kp6ejnbt2uH+/fsYP348qlevjrVr1+LVV1/Fxo0b0bt3b73tP/jgA1hZWWHy5MnIzMzERx99hEGDBuHIkSNFnmdx37N79+4hICAAiYmJeOONN/Dcc88hIyMDW7ZswfXr1+Hq6gqNRoNXXnkF8fHx6N+/PyZMmIC7d+9i165dOH36NHx8fIr9/ms9evQIQUFB6NChAxYuXKiLp7h/oydPnkRAQAAqVaqEUaNGwdvbG5cuXcKPP/6I999/H507d4aXlxe+/vrrAu/p119/DR8fH7Rt27bEcRMR8TsEv0OU9+8QhsyZMwdz585FYGAgRo8ejXPnzmHFihX4/fffceDAAVSqVAm5ubkICgpCTk4Oxo0bBw8PD6SkpOCnn37CnTt34OzsjL/++guvvPIKWrZsiXnz5sHW1hYXL17EgQMHShwTmQGJyEjGjBkjPfkn1qlTJwmAFB0dXWD7+/fvF2j7z3/+Izk4OEgPHjzQtQ0dOlSqU6eO7nFSUpIEQKpevbp0+/ZtXfsPP/wgAZB+/PFHXdvs2bMLxARAsrGxkS5evKhrO3HihARAWrp0qa4tODhYcnBwkFJSUnRtFy5ckKytrQsc0xBD5xcZGSmpVCrp6tWreucHQJo3b57ets8++6zk5+ene7x582YJgPTRRx/p2h49eiQFBARIAKTVq1cXGU9ERIRUqVIlvfcsJydHcnFxkd54440i4z506JAEQPryyy91bXv27JEASHv27NE7l8d/VyWJ2dDrbtiwQQIg/fbbb7q2jz/+WAIgJSUlFdi+Tp060tChQ3WPJ06cKAGQ9u3bp2u7e/euVLduXcnb21vSaDR659KkSRMpJydHt+2SJUskANKpU6cKvNbjivuezZo1SwIgxcXFFdg+Ly9PkiRJiomJkQBIixcvLnQbQ++9JOX/23j8fdX+fU2bNq1YcRv6G+3YsaNUpUoVvbbH45Ek8fdla2sr3blzR9d248YNydraWpo9e3aB1yEiehy/Qzz9/Pgdonx+h1i9erVeTDdu3JBsbGykl19+WfcakiRJy5YtkwBIMTExkiRJ0p9//ikBkL777rtCj/3JJ59IAKSbN28WGQNZBg6tJ5OztbVFWFhYgXZ7e3vd/bt37yIjIwMBAQG4f/8+zp49+9TjhoSEoGrVqrrHAQEBAMQwqKcJDAzU69ls2bIlnJycdPtqNBrs3r0bvXr1Qs2aNXXb1a9fH926dXvq8QH988vOzkZGRgbatWsHSZLw559/Ftj+zTff1HscEBCgdy7btm2DtbW17uo6AKjVaowbN65Y8YSEhODhw4eIi4vTte3cuRN37txBSEiIwbgfPnyIW7duoX79+nBxccGxY8eK9Vqlifnx133w4AEyMjLwf//3fwBQ4td9/PXbtGmDDh066NocHR0xatQoXLlyBWfOnNHbPiwsDDY2NrrHxf2bKu57tmnTJvj6+ha4ig9AN9Ry06ZNcHV1NfgelWUZpMd/B4biLuxv9ObNm/jtt9/wxhtv4Jlnnik0ntDQUOTk5GDjxo26ttjYWDx69Oipc16JiArD7xD8DlHev0M8affu3cjNzcXEiRP1iu+NHDkSTk5OuqH9zs7OAMT0hvv37xs8lrag3w8//GD0QoJkfEzkyeRq1aql9x+b1l9//YXevXvD2dkZTk5OcHNz033hf3xuT2GeTCq0H8j//PNPiffV7q/d98aNG/j3339Rv379AtsZajMkOTkZw4YNQ7Vq1XRz1jp16gSg4PnZ2dkVGNr1eDyAmHfm6ekJR0dHve0aNWpUrHh8fX3RuHFjxMbG6tpiY2Ph6uqKF198Udf277//YtasWfDy8oKtrS1cXV3h5uaGO3fuFOv38riSxHz79m1MmDAB7u7usLe3h5ubG+rWrQugeH8Phb2+odfSVkG+evWqXntp/6aK+55dunQJzZs3L/JYly5dQqNGjWQtsGRtbY3atWsXaC/O36j2C8jT4m7cuDGef/55fP3117q2r7/+Gv/3f/9X7H8zRERP4ncIfoco798hDL0uUPA8bWxsUK9ePd3zdevWRXh4OP773//C1dUVQUFBWL58ud75hoSEoH379hgxYgTc3d3Rv39/fPvtt0zqLRTnyJPJPX6VVOvOnTvo1KkTnJycMG/ePPj4+MDOzg7Hjh3D1KlTi/UfjFqtNtguSZJR9y0OjUaDLl264Pbt25g6dSoaN26MypUrIyUlBcOGDStwfoXFI7eQkBC8//77yMjIQJUqVbBlyxYMGDBAL2kcN24cVq9ejYkTJ6Jt27ZwdnaGSqVC//79jfof/+uvv46DBw9iypQpaNWqFRwdHZGXl4euXbua7AOntH8Xpn7PCuuZf7KwkZatrW2BJXVK+jdaHKGhoZgwYQKuX7+OnJwcHD58GMuWLSvxcYiItPgdgt8hisOSv0OUxaJFizBs2DD88MMP2LlzJ8aPH4/IyEgcPnwYtWvXhr29PX777Tfs2bMHW7duxY4dOxAbG4sXX3wRO3fuNNnfDsmDiTyZhb179+LWrVuIi4tDx44dde1JSUkKRpWvRo0asLOzM1httDgVSE+dOoXz589j7dq1CA0N1bXv2rWr1DHVqVMH8fHxuHfvnt7V6XPnzhX7GCEhIZg7dy42bdoEd3d3ZGVloX///nrbbNy4EUOHDsWiRYt0bQ8ePChWZdvSxvzPP/8gPj4ec+fOxaxZs3TtFy5cKHDMkgwvr1OnjsH3Rzvssk6dOsU+VlGK+575+Pjg9OnTRR7Lx8cHR44cwcOHDwstuKS9yv/k8Z/sHShKcf9G69WrBwBPjRsA+vfvj/DwcGzYsAH//vsvKlWqpDfkkohIDvwOUXL8DiGY43cIQ68LiPPUfgYDQG5uLpKSkhAYGKi3fYsWLdCiRQvMmDEDBw8eRPv27REdHY333nsPAGBlZYWXXnoJL730EhYvXowFCxZg+vTp2LNnT4FjkXnj0HoyC9orgI9fpczNzcVnn32mVEh61Go1AgMDsXnzZvz999+69osXL2L79u3F2h/QPz9JkrBkyZJSx9S9e3c8evQIK1as0LVpNBosXbq02Mdo0qQJWrRogdjYWMTGxsLT01PvS5A29ievHi9durTQ3l45Yjb0fgFAVFRUgWNq1z8vzpeC7t27IyEhQW/ps+zsbHzxxRfw9vZG06ZNi3sqRSrue9a3b1+cOHHC4DJt2v379u2LjIwMgz3Z2m3q1KkDtVqN3377Te/5kvz7Ke7fqJubGzp27IiYmBgkJycbjEfL1dUV3bp1w1dffYWvv/4aXbt21VUFJiKSC79DlBy/Qwjm+B3iSYGBgbCxscGnn36qd06rVq1CZmYmevToAQDIysrCo0eP9PZt0aIFrKyskJOTA0BMOXhSq1atAEC3DVkO9siTWWjXrh2qVq2KoUOHYvz48VCpVFi3bp1Rhx+V1Jw5c7Bz5060b98eo0ePhkajwbJly9C8eXMcP368yH0bN24MHx8fTJ48GSkpKXBycsKmTZtKPE/qccHBwWjfvj2mTZuGK1euoGnTpoiLiyvx3K+QkBDMmjULdnZ2GD58eIEh16+88grWrVsHZ2dnNG3aFIcOHcLu3bt1S+oYI2YnJyd07NgRH330ER4+fIhatWph586dBntX/Pz8AADTp09H//79UalSJQQHB+s+nB83bdo0bNiwAd26dcP48eNRrVo1rF27FklJSdi0aVOBcy+t4r5nU6ZMwcaNG9GvXz+88cYb8PPzw+3bt7FlyxZER0fD19cXoaGh+PLLLxEeHo6EhAQEBAQgOzsbu3fvxltvvYWePXvC2dkZ/fr1w9KlS6FSqeDj44OffvoJN27cKHbMJfkb/fTTT9GhQwc899xzGDVqFOrWrYsrV65g69atBf4thIaG4rXXXgMAzJ8/v+RvJhHRU/A7RMnxO4Rgjt8hnuTm5oaIiAjMnTsXXbt2xauvvopz587hs88+w/PPP6+rBfHLL79g7Nix6NevHxo2bIhHjx5h3bp1UKvV6Nu3LwBg3rx5+O2339CjRw/UqVMHN27cwGeffYbatWvrFfEjy8BEnsxC9erV8dNPP+Htt9/GjBkzULVqVQwePBgvvfSSbi1Spfn5+WH79u2YPHkyZs6cCS8vL8ybNw+JiYlPrYhbqVIl/Pjjj7q5SnZ2dujduzfGjh0LX1/fUsVjZWWFLVu2YOLEifjqq6+gUqnw6quvYtGiRXj22WeLfZyQkBDMmDED9+/fNzjsecmSJVCr1fj666/x4MEDtG/fHrt37y7V76UkMa9fvx7jxo3D8uXLIUkSXn75ZWzfvl2v4i8APP/885g/fz6io6OxY8cO5OXlISkpyeCHsLu7Ow4ePIipU6di6dKlePDgAVq2bIkff/xRd0VbDsV9zxwdHbFv3z7Mnj0b33//PdauXYsaNWrgpZde0hWjU6vV2LZtG95//32sX78emzZtQvXq1dGhQwe0aNFCd6ylS5fi4cOHiI6Ohq2tLV5//XV8/PHHTy1Kp1WSv1FfX18cPnwYM2fOxIoVK/DgwQPUqVMHr7/+eoHjBgcHo2rVqsjLy8Orr75a0reSiOip+B2i5PgdQjDH7xCGzJkzB25ubli2bBkmTZqEatWqYdSoUViwYIFu2p2vry+CgoLw448/IiUlBQ4ODvD19cX27dt1FftfffVVXLlyBTExMcjIyICrqys6deqEuXPn6qrek+VQSeZ0uZLIAvXq1Qt//fWXwblXRBXdo0ePULNmTQQHB2PVqlVKh0NEZFb4HYKISotz5IlK4N9//9V7fOHCBWzbtg2dO3dWJiAiM7d582bcvHlTr0ATEVFFxO8QRCQn9sgTlYCnpyeGDRumW7dzxYoVyMnJwZ9//okGDRooHR6R2Thy5AhOnjyJ+fPnw9XVFceOHVM6JCIiRfE7BBHJiXPkiUqga9eu2LBhA9LS0mBra4u2bdtiwYIF/AAmesKKFSvw1VdfoVWrVlizZo3S4RARKY7fIYhITuyRJyIiIiIiIrIgnCNPREREREREZEGYyBMRERERERFZEM6RNyAvLw9///03qlSpApVKpXQ4REREkCQJd+/eRc2aNWFlxevwZcXPeiIiMjcl+axnIm/A33//DS8vL6XDICIiKuDatWuoXbu20mFYPH7WExGRuSrOZz0TeQOqVKkCQLyBTk5OCkdDREQEZGVlwcvLS/cZRWXDz3oiIjI3JfmsZyJvgHaInZOTEz/ciYjIrHAYuDz4WU9EROaqOJ/1nGRHREREREREZEGYyBMREZHili9fDm9vb9jZ2cHf3x8JCQlFbh8VFYVGjRrB3t4eXl5emDRpEh48eGCiaImIiJTFRJ6IiIgUFRsbi/DwcMyePRvHjh2Dr68vgoKCcOPGDYPbr1+/HtOmTcPs2bORmJiIVatWITY2Fu+++66JIyciIlIG58gTERGRohYvXoyRI0ciLCwMABAdHY2tW7ciJiYG06ZNK7D9wYMH0b59ewwcOBAA4O3tjQEDBuDIkSMmjZuIyi+NRoOHDx8qHQaVM2q1GtbW1rLUu2EiT0RERIrJzc3F0aNHERERoWuzsrJCYGAgDh06ZHCfdu3a4auvvkJCQgLatGmDy5cvY9u2bRgyZEihr5OTk4OcnBzd46ysLPlOgojKlXv37uH69euQJEnpUKgccnBwgKenJ2xsbMp0HCbyREREpJiMjAxoNBq4u7vrtbu7u+Ps2bMG9xk4cCAyMjLQoUMHSJKER48e4c033yxyaH1kZCTmzp0ra+xEVP5oNBpcv34dDg4OcHNz40ohJBtJkpCbm4ubN28iKSkJDRo0gJVV6We6M5EnIiIii7J3714sWLAAn332Gfz9/XHx4kVMmDAB8+fPx8yZMw3uExERgfDwcN1j7Vq9RESPe/jwISRJgpubG+zt7ZUOh8oZe3t7VKpUCVevXkVubi7s7OxKfSwm8kRERKQYV1dXqNVqpKen67Wnp6fDw8PD4D4zZ87EkCFDMGLECABAixYtkJ2djVGjRmH69OkGezhsbW1ha2sr/wkQUbnEnngylrL0wusdR5ajEBEREZWCjY0N/Pz8EB8fr2vLy8tDfHw82rZta3Cf+/fvF/gipFarAYBzWomIqEJgjzwREREpKjw8HEOHDkXr1q3Rpk0bREVFITs7W1fFPjQ0FLVq1UJkZCQAIDg4GIsXL8azzz6rG1o/c+ZMBAcH6xJ6IiKi8oyJPBERESkqJCQEN2/exKxZs5CWloZWrVphx44dugJ4ycnJej3wM2bMgEqlwowZM5CSkgI3NzcEBwfj/fffV+oUiIj0aDTAvn1Aairg6QkEBACWdp3R29sbEydOxMSJE4u1/d69e/HCCy/gn3/+gYuLi1FjI0AlcQxaAVlZWXB2dkZmZiacnJyUDoeIiIifTTLj+0lEhjx48ABJSUmoW7duqQuRxcUBEyYA16/nt9WuDSxZAvTpI1Ogj3nafP7Zs2djzpw5JT7uzZs3UblyZTg4OBRr+9zcXNy+fRvu7u5GrTFg6RcMivobK8lnE3vkiYiIiIiIZBAXB7z2GvBkV2lKimjfuFH+ZD41NVV3PzY2FrNmzcK5c+d0bY6Ojrr7kiRBo9HA2vrpaaCbm1uJ4rCxsSm0SCnJj8XuiIiIiMpAowH27gU2bBA/NRqlIyIiJWg0oife0HhnbdvEifL/H+Hh4aG7OTs7Q6VS6R6fPXsWVapUwfbt2+Hn5wdbW1vs378fly5dQs+ePeHu7g5HR0c8//zz2L17t95xvb29ERUVpXusUqnw3//+F71794aDgwMaNGiALVu26J7fu3cvVCoV7ty5AwBYs2YNXFxc8PPPP6NJkyZwdHRE165d9S48PHr0COPHj4eLiwuqV6+OqVOnYujQoejVq1ep349//vkHoaGhqFq1KhwcHNCtWzdcuHBB9/zVq1cRHByMqlWronLlymjWrBm2bdum23fQoEG65QcbNGiA1atXlzoWY2IiT0RERFRKcXGAtzfwwgvAwIHip7e3aCeiimXfPv3h9E+SJODaNbGdqU2bNg0ffPABEhMT0bJlS9y7dw/du3dHfHw8/vzzT3Tt2hXBwcFITk4u8jhz587F66+/jpMnT6J79+4YNGgQbt++Xej29+/fx8KFC7Fu3Tr89ttvSE5OxuTJk3XPf/jhh/j666+xevVqHDhwAFlZWdi8eXOZznXYsGH4448/sGXLFhw6dAiSJKF79+54+PAhAGDMmDHIycnBb7/9hlOnTuHDDz/UjVqYOXMmzpw5g+3btyMxMRErVqyAq6trmeIxFg6tJyIiIioFJYbQEpH5eqyjWZbt5DRv3jx06dJF97hatWrw9fXVPZ4/fz6+//57bNmyBWPHji30OMOGDcOAAQMAAAsWLMCnn36KhIQEdO3a1eD2Dx8+RHR0NHx8fAAAY8eOxbx583TPL126FBEREejduzcAYNmyZbre8dK4cOECtmzZggMHDqBdu3YAgK+//hpeXl7YvHkz+vXrh+TkZPTt2xctWrQAANSrV0+3f3JyMp599lm0bt0agBiVYK7YI09ERGQEubnAggVAER0VZMGUGkJLRObL01Pe7eSkTUy17t27h8mTJ6NJkyZwcXGBo6MjEhMTn9oj37JlS939ypUrw8nJCTdu3Ch0ewcHB10SDwCenp667TMzM5Geno42bdronler1fDz8yvRuT0uMTER1tbW8Pf317VVr14djRo1QmJiIgBg/PjxeO+999C+fXvMnj0bJ0+e1G07evRofPPNN2jVqhXeeecdHDx4sNSxGBsTeSIiIpmdOgX4+wPTpwNjxigdDRmDOQ+hJSJlBASI6vSFFWxXqQAvL7GdqVWuXFnv8eTJk/H9999jwYIF2LdvH44fP44WLVogNze3yONUqlRJ77FKpUJeXl6Jtld60bQRI0bg8uXLGDJkCE6dOoXWrVtj6dKlAIBu3brh6tWrmDRpEv7++2+89NJLelMBzAkTeSIiIploNMDHHwOtWwPHjwPVqwN9+yodFRmDOQ+hJSJlqNViiTmgYDKvfRwVZR7ryR84cADDhg1D79690aJFC3h4eODKlSsmjcHZ2Rnu7u74/fffdW0ajQbHjh0r9TGbNGmCR48e4ciRI7q2W7du4dy5c2jatKmuzcvLC2+++Sbi4uLw9ttvY+XKlbrn3NzcMHToUHz11VeIiorCF198Uep4jIlz5ImIiGRw6RIwbBiwf794/MorwMqVAFfiKZ/MeQgtESmnTx9RH8PQOvJRUeZTN6NBgwaIi4tDcHAwVCoVZs6cWWTPurGMGzcOkZGRqF+/Pho3boylS5fin3/+KdY69KdOnUKVKlV0j1UqFXx9fdGzZ0+MHDkSn3/+OapUqYJp06ahVq1a6NmzJwBg4sSJ6NatGxo2bIh//vkHe/bsQZMmTQAAs2bNgp+fH5o1a4acnBz89NNPuufMDRN5IiKiMpAkkbCHhwPZ2YCjo+iRCQsrfHglWT7tENqUFMPz5FUq8bwSQ2iJSFl9+gA9e4qpNamp4oJeQIB59MRrLV68GG+88QbatWsHV1dXTJ06FVlZWSaPY+rUqUhLS0NoaCjUajVGjRqFoKAgqIvxZnXs2FHvsVqtxqNHj7B69WpMmDABr7zyCnJzc9GxY0ds27ZNN8xfo9FgzJgxuH79OpycnNC1a1d88sknAAAbGxtERETgypUrsLe3R0BAAL755hv5T1wGKknpSQpmKCsrC87OzsjMzISTk5PS4RARkZn6+29gxAhg+3bxuGNHYM0aoG5d+V+Ln03ykuP91FatB/STee0FHFatJ7I8Dx48QFJSEurWrQs7Ozulw6lw8vLy0KRJE7z++uuYP3++0uEYRVF/YyX5bOIceSIiolKIjQWaNxdJvK0tsGgRsGePcZJ4Mk/aIbS1aum3167NJJ6IqDiuXr2KlStX4vz58zh16hRGjx6NpKQkDBw4UOnQzB6H1hMREZXA7duiEr12pN1zzwHr1gGP1dChCsQShtASEZkrKysrrFmzBpMnT4YkSWjevDl2795ttvPSzQkTeSIiomLasQN44w2RsKnVYnm5GTOAJ1bXoQpGrQY6d1Y6CiIiy+Pl5YUDBw4oHYZFYiJPRET0FPfuAZMnA59/Lh43agR8+SXQpo2ycREREVHFxDnyRERERThwAPD1zU/iJ0wAjh1jEk9ERETKYSJPRERkQE4OMHWqmO98+TLg5QXEx4t1gB0clI6OiIiIKjIOrSciInrC8eNAaChw6pR4PHSoWBve2VnRsIiIiIgAsEeeiIhI59EjIDJSDJs/dQpwcwO+/16sDc8knoiIiMwFe+QtTFYWsGWLWO6mogztPHsWSEkBXnpJ6UgMy80FvvoKuHtXvmOqVMALLwAtWsh3zIpEksQa3+npSkdiWlWqAK+/Djg6Kh1JQZIkKr7XrQs0bqx0NIYlJQGDBgGHDonHvXqJefE1aigaFhEREVEBTOQtiEYD9O4N/PILEBcHbNokEr7yLDsb6NQJuHED2LPHPJf3WbAAmDtX/uOq1cC77wIzZ3Jpq5L68ktg2DClo1DG++8Da9cCHTooHUm+lBRg+HDg558BJycxbL1uXaWj0nf3LhAUBFy4IGJcuhQYMqT8/x9LRESk1blzZ7Rq1QpRUVEAAG9vb0ycOBETJ04sdB+VSoXvv/8evXr1KtNry3WcioSJvAX56CORxANiqOfnnwNvvqlsTMb2+eciiQeA+fPNL5HPzBSFrwCgWzf5ht7euCF+1/PnA1u3AuvWAU2bynPs8k6jEcksIIqU1aqlbDymdOCAKMrWsSMwZQowbx5ga6tcPJIEfPMN8NZbwJ07oi0rCxgwANi3z7wuUI0bJ5L42rWB/fuBOnWUjoiIiKh4goOD8fDhQ+zYsaPAc/v27UPHjh1x4sQJtGzZskTH/f3331G5cmW5wgQAzJkzB5s3b8bx48f12lNTU1G1alVZX+tJa9aswcSJE3FH+6XEwjGRtxCHD4ueWQB4+WVg505g0iTR69a8ubKxGcuDB8DHH+c//uUX4OBBoF075WJ60vLlIplv0gT46SfASsaqE7GxIgE6dgx47jnR8z9xoryvUR59+61IyKpVA7ZtM89h5saSmSmWRlu7Vlz4275djE5o1cr0sdy6Jf5+v/1WPG7dWlxgCQkBjhwBZs8Wf9Pm4OuvxXtmZQWsX88knoiILMvw4cPRt29fXL9+HbVr19Z7bvXq1WjdunWJk3gAcHNzkyvEp/Lw8DDZa5UXTAkswJ07ogdLowH69xdfzrt2FYlu//7A/ftKR2gcMTFAWppY8mnIENGm7Wk1B9nZwOLF4v706fIn2CEhothWt25iGay33wZefBG4ckXe1ylP8vLy/0YmTapYSTwgRoSsWSNG7Li5ib+fNm1E8bZHj0wXx9at4gLjt9+KKSJz5oiLcC+/DKxcKbb54AOxlJvSLl3KH9k0a5YYxUFERKQlSeI7nxI3SSpejK+88grc3NywZs0avfZ79+7hu+++w/Dhw3Hr1i0MGDAAtWrVgoODA1q0aIENGzYUeVxvb2/dMHsAuHDhAjp27Ag7Ozs0bdoUu3btKrDP1KlT0bBhQzg4OKBevXqYOXMmHj58CED0iM+dOxcnTpyASqWCSqXSxaxSqbB582bdcU6dOoUXX3wR9vb2qF69OkaNGoV79+7pnh82bBh69eqFhQsXwtPTE9WrV8eYMWN0r1UaycnJ6NmzJxwdHeHk5ITXX38d6Y8VXDpx4gReeOEFVKlSBU5OTvDz88Mff/wBALh69SqCg4NRtWpVVK5cGc2aNcO2bdtKHUtxMJE3c5IkvmReuSLmlEZHi4Rx7VrA3R346y+R4JU3ubniiz4g1nGeNUuc97ZtwNGjysamFR0teh19fETSbQw1a4qk6IsvgMqVgV9/FQXwVq0q/n/uFcnmzeLfhJMTMHas0tEop1cv4PRp8fPhQ1FrISBAjFQwprt3gVGjgFdeERfhmjQRo4lmz84fRv/aa2IbSQIGDwZu3jRuTEXJzRUXQ+/dE+/P9OnKxUJERObp/n3RMaDErbidddbW1ggNDcWaNWsgPfYF8bvvvoNGo8GAAQPw4MED+Pn5YevWrTh9+jRGjRqFIUOGICEhoVivkZeXhz59+sDGxgZHjhxBdHQ0pk6dWmC7KlWqYM2aNThz5gyWLFmClStX4pNPPgEAhISE4O2330azZs2QmpqK1NRUhBj4Ep2dnY2goCBUrVoVv//+O7777jvs3r0bY5/4crdnzx5cunQJe/bswdq1a7FmzZoCFzOKKy8vDz179sTt27fx66+/YteuXbh8+bJefIMGDULt2rXx+++/4+jRo5g2bRoq/e8LzpgxY5CTk4PffvsNp06dwocffghHY/coSVRAZmamBEDKzMxUOhTpv/+VJECSrK0l6fBh/ed27hTPAZK0caMy8RmL9rw9PCTp339F2+DBoq13b2VjkyRJun9fxAZI0qpVpnnNS5ckqUOH/N/5K69IUmqqaV7bEuTlSdKzz4r3ZsYMpaMxD3l5krR2rSQ5OYn3xcFBkpYvF+1y+/VXSapbV7yOSiVJkyaJfyeGZGdLUtOmYtvu3SVJo5E/nuKYMkXEULWqJCUnKxNDSZjTZ1N5wPeTiAz5999/pTNnzkj//u8L6L17+d+9TH27d6/4cScmJkoApD179ujaAgICpMGDBxe6T48ePaS3335b97hTp07ShAkTdI/r1KkjffLJJ5IkSdLPP/8sWVtbSykpKbrnt2/fLgGQvv/++0Jf4+OPP5b8/Px0j2fPni35+voW2O7x43zxxRdS1apVpXuPvQFbt26VrKyspLS0NEmSJGno0KFSnTp1pEePHum26devnxQSElJoLKtXr5acnZ0NPrdz505JrVZLyY99Ifjrr78kAFJCQoIkSZJUpUoVac2aNQb3b9GihTRnzpxCX/txT/6NPa4kn03skTdjiYnA+PHi/nvvAf7++s936SJ6qwFgxAggOdm08RmLdh1nQBTssrMT9yMiRAXp778XvY1K0g77f+YZ0atoCvXqAXv3irnPNjZiTn7z5mL1AhJTTv78U4xcmDBB6WjMg0oFhIaKIfYvviiu7I8ZI6qzX78uz2s8eCD+nXbuLJZvq1NH1LNYvBiwtze8j4ODKIJnZydG2Xz6qTyxlMTOnfk1OGJixBQeIiKiJzk4iJFbStxKstR048aN0a5dO8TExAAALl68iH379mH48OEAAI1Gg/nz56NFixaoVq0aHB0d8fPPPyO5mAlEYmIivLy8ULNmTV1b27ZtC2wXGxuL9u3bw8PDA46OjpgxY0axX+Px1/L19dUrtNe+fXvk5eXh3LlzurZmzZpBrVbrHnt6euKGtkp2CWnPz+uxLwRNmzaFi4sLEhMTAQDh4eEYMWIEAgMD8cEHH+DSpUu6bcePH4/33nsP7du3x+zZs3Hy5MlSxVESTOTN1IMHYl78/ftAYKD4omzI/PliDuydO2L9Y1POgzWW2Fgxb7V6deA//8lvb9oU6NtX3FeySFZuLvDhh+L+1KkiqTYVtVr8LfzxhyhgduuWGKo8ZEh+VfCKSJLEvwUAGD0acHVVNh5z88wzwK5dImG2sxP3W7QQRd7KMkXjzz9FEbuFC8Vx3ngDOHmyeKtLtGiRX2PinXdEUUdTSU8XFzgAUZCPK90QEVFhVCrRSaDEraRLoA4fPhybNm3C3bt3sXr1avj4+KBTp04AgI8//hhLlizB1KlTsWfPHhw/fhxBQUHIzc2V7b06dOgQBg0ahO7du+Onn37Cn3/+ienTp8v6Go+r9MTyNyqVCnl5eUZ5LUBU3P/rr7/Qo0cP/PLLL2jatCm+//57AMCIESNw+fJlDBkyBKdOnULr1q2xdOlSo8UCMJE3W++8A5w4IQpWffll4YXUKlUCNmwAqlQRSyZpkxlL9XixsvBw8Z/Y47RzWGNjgfPnTRub1pdfAteuAZ6eInFRQosWovK3tsjeV1+J3nkDNUcqhF9+EXOx7ezKZ80IOVhZiSXW/vwTeP55ceFn8GDg9deBjIySHevRIzFKqE0bUZOgRg1gyxZRu8HJqfjHefNNoHdvMY9fO1fd2PLygKFDRTLfooW4CEFERFQevP7667CyssL69evx5Zdf4o033oDqf1cDDhw4gJ49e2Lw4MHw9fVFvXr1cL4EX6abNGmCa9euITU1Vdd2+PBhvW0OHjyIOnXqYPr06WjdujUaNGiAq1ev6m1jY2MDjUbz1Nc6ceIEsrOzdW0HDhyAlZUVGjVqVOyYS0J7fteuXdO1nTlzBnfu3EHTx9aAbtiwISZNmoSdO3eiT58+WL16te45Ly8vvPnmm4iLi8Pbb7+NldoKv0bCRN4M/fgjoL2As2aNSBiLUq+eWG8dEF+uf/3VqOEZVVycmFLg4mK4WFmrVkBwsPgyrh1+b0qFDftXgo2N+H0fOAA0aACkpIiq4GPHikqnFcl774mfI0cCXL2kaI0biwry8+YB1tbAxo3iItBPPxVv/3PnxLKXM2eKfw99+oipLsHBJY9FpQL++1+xdvuFC+JCg7EtXgz8/LMY9v/NN4UP/yciIrI0jo6OCAkJQUREBFJTUzFs2DDdcw0aNMCuXbtw8OBBJCYm4j//+Y9eRfanCQwMRMOGDTF06FCcOHEC+/btw/QnqsQ2aNAAycnJ+Oabb3Dp0iV8+umnuh5rLW9vbyQlJeH48ePIyMhATk5OgdcaNGgQ7OzsMHToUJw+fRp79uzBuHHjMGTIELi7u5fsTXmCRqPB8ePH9W6JiYkIDAxEixYtMGjQIBw7dgwJCQkIDQ1Fp06d0Lp1a/z7778YO3Ys9u7di6tXr+LAgQP4/fff0aRJEwDAxIkT8fPPPyMpKQnHjh3Dnj17dM8ZTbFm5FcwShbAuX5dkqpXFwUuJk0q2b7Dhon9atWSpIwM48RnTHl5kuTrK85h1qzCtzt8WGyjVktSUpKpohPWrROv7epasgIkxnbvniSNHZtfHKV+fUk6eFDpqExj3z5xzpUqWUbBMnPyxx/5RecASRo+XJIK+29Po5GkpUslyd5ebOvsLP49yFE479dfJcnKShz366/LfrzCJCSIwqGAJH3+ufFex1hYnE1efD+JyJCiCpFZgoMHD0oApO7du+u137p1S+rZs6fk6Ogo1ahRQ5oxY4YUGhoq9ezZU7dNUcXuJEmSzp07J3Xo0EGysbGRGjZsKO3YsaNAsbspU6ZI1atXlxwdHaWQkBDpk08+0Ssw9+DBA6lv376Si4uLBEBavXq1JElSgeOcPHlSeuGFFyQ7OzupWrVq0siRI6W7d+/qnh86dKhe7JIkSRMmTJA6depU6HuzevVqCUCBm4+PjyRJknT16lXp1VdflSpXrixVqVJF6tevn664Xk5OjtS/f3/Jy8tLsrGxkWrWrCmNHTtW93cyduxYycfHR7K1tZXc3NykIUOGSBmFJGRyFbtjIm+AUh/ujx5JUufO4kvmc89J0oMHJdv/7l1JathQ7N+zp3EqUxvTli0idkdHSbp1q+htu3QR2/7nP6aJTZLE76dxY/G6CxaY7nVLYudOcSEHEInRu+9KUk6O0lEZV9eu4nxHjlQ6Esv077+S9PbbotI8IEne3iKxflxysiQFBuYn/IGB8l80mT1bHLtKFUm6eFHeY0uSuEDh4yNeo29fy/v/UZKYeMqN7ycRGWLpiTyZP1atL4c++EBUJa9cWcx7t7Ut2f6OjmKoqI0N8MMPwGefGSVMo5Ck/OHRY8YA1aoVvf3MmeLn6tXyVd9+mrg44OxZMex/zBjTvGZJdekiKpQPHiymHyxYIFY7OHVK6ciM4/ffgR07RBHAadOUjsYy2dmJeeJ79gDe3sCVK6JY3eTJoujmunViLvnu3WIY+rJlYmi63FXeZ8wQa7nfvSsKfcpdF2fMGFFE85lngJUrS15AiIiIiMicqCSpLDWLy6esrCw4OzsjMzMTTiWp3FQGBw8CHTsCGo2YFz90aOmPFRUFTJokLgQkJAAtW8oVpfHs2iXmd9vbi0SiRo2n79OpE/Dbb2Kpsago48YnSWJ+/smTwOzZwJw5xn09OWzaJKr+37olLu6EhYmiiHJxdQUmTiz5BSc59eolLlqFhgJr1yoXR3lx964oMvnf/4rH1auLvx9AXBD68kugYUPjvf61a4CvL/DPP6Lgp3Z1iLL68kvxf6paLWqItG8vz3FNTYnPpvKM7ycRGfLgwQMkJSWhbt26sFOyGBKVW0X9jZXos0n+wQIls2zZMqlOnTqSra2t1KZNG+nIkSOFbpubmyvNnTtXqlevnmRrayu1bNlS2r59u942s2fPLjDvoVGjRiWKydTD7f75R5KeeUYM+Rw0qOxDPvPyJKlHD3G8Jk0kKTtbljCNKiBAxPvYtJyn2rlT7GNvL0n/m75iNCUZ9m9OUlMlKTg4f0i03Ldx45Q7txMnRAwqlSQlJioXR3n044+S5O4u3l9ra0l67z1JevjQNK8dF5f/9/Xzz2U/3rlzklS5sjje/PllP56SOBRcXnw/icgQDq0nY5NraL21ES4yFFtsbCzCw8MRHR0Nf39/REVFISgoCOfOnUMNA12yM2bMwFdffYWVK1eicePG+Pnnn9G7d28cPHgQzz77rG67Zs2aYffu3brH1taKnmaRJAkYNQpITgZ8fMRw+LIO+VSpxJBzX19RAX7iROCLL2QJ1yh++w3Yt0/0Gk+ZUvz9AgPF8lcJCaIStVy9d096fI3y4gz7NyceHqLHetMm8T7JJTtb/K0uXSqG85emYnlZaZcp7NdPVGIn+bzyiqhEv3q1GCnj62u61+7dGxg9GlixQoy0OHECKG2B2pwcMUw/O1tMF4iIkDVUIiIiIuUY4ypDcbVp00YaM2aM7rFGo5Fq1qwpRUZGGtze09NTWrZsmV5bnz59pEGDBukez549W/L19S1TXKa8Sv/FF/m9XgkJ8h579+78AlbffivvseWkLVz35psl3/fHH/N7yo1Vqf/nn/N7/tPTjfMalmjSJPG+VK8uVlswpcTE/L/tEydM+9pkfPfvS1Lz5uL327WrqJhfGuHh4hjVqpn+b9QY2IMsL76fRGSItrf0/v37SodC5dT9+/ctu9hdbm4ujh49isDAQF2blZUVAgMDcejQIYP75OTkFJhHYG9vj/379+u1XbhwATVr1kS9evUwaNAgJCcnFxlLTk4OsrKy9G6mcOaMmN8NiKJkzz8v7/Ffeim/ANjIkWLuubk5ckTMj1ergalTS75/jx6it/DePeDTT+WPD8gvwvef/xRv7n5FERkJPPecmEM9eLCo72DK15YkoGdPy6gBQSWjXePdzk4UM/zkk5IfY/t2MVIHECMLatWSN0YiIiqf1Go1AJGrEBnD/fv3AQCVKlUq03EUK3b3999/o1atWjh48CDatm2ra3/nnXfw66+/4siRIwX2GThwIE6cOIHNmzfDx8cH8fHx6NmzJzQaDXJycgAA27dvx71799CoUSOkpqZi7ty5SElJwenTp1GlkEpfc+bMwdy5cwu0G7MAzr//5lcTf/ll8aXTygiXVR4+FEX0Dh8G2rYVw9jNaaZBcDDw00/AsGHiy3ZpbNwohlc7OwNXr4qfcvn1VzEk18YGuHyZycCTzp8XyXx2trjgMX268V/z8mVRcE2jEVXrW7c2/muSMj7/HHjzTaBSJVEQtLi/69RUcYHv5k1g7FgxBaQ8YHE2efH9JCJDJElCcnIyHj58iJo1a8LKGF/QqUKSJAn379/HjRs34OLiAk9PzwLblOSzyaIS+Zs3b2LkyJH48ccfoVKp4OPjg8DAQMTExODff/81+Dp37txBnTp1sHjxYgwfPtzgNjk5OboLAYB4A728vIz64T52LLB8uejhPXFCzGU2lqQkUXE9K0ss8aSd7620P/8USaCVlZjLX9pq2Hl5QPPm4hjvvw+8+658MXbpIpbdGj3aspbzM6XHK4L/9hvQrp1xX2/UKLF8WNeu4gIYlV+SJC7SbdoE1K8PHDv29JUX8vKAoCDx77ZlSzHqp7wUHWbiKS++n0RUmNzcXCQlJSEvL0/pUKgccnFxgYeHB1QGCqOV5LNJsb5ZV1dXqNVqpKen67Wnp6fDo5Cs1s3NDZs3b8aDBw9w69Yt1KxZE9OmTUO9evUKfR0XFxc0bNgQFy9eLHQbW1tb2JpwDa0ffhBJPCCSIGMm8QBQt64odte/v0h0X3wReOEF475mcSxYIH6GhJRtSSsrK9ETPHiwGEo7YQJQuXLZ4zt8WCQD1tZiKSwybMgQYOdO4OuvRWGxEycAFxfjvNa1a2J5RkBclKLyTaUSF21+/x24eFEUm/zyy6L3+fhj8e/WwSF/eD4REVFJ2NjYoEGDBhxeT7KrVKmSbvpGWSmWyNvY2MDPzw/x8fHo1asXACAvLw/x8fEYO3Zskfva2dmhVq1aePjwITZt2oTXX3+90G3v3buHS5cuYciQIXKGX2rXrwNvvCHuT54seo5MISREzEVftUokvCdOiHXAlXLmjOhlA+TpQQ8JEeu7X7okhuOGh5f9mNqq6EOGAN7eZT9eeaVSidEKhw+L93/UKCA2tuyrLxjy8cdiukjnzpa7FjiVTNWqwPr1YorQunVilExh/50fOZJ/gefTT4EmTUwXJxERlS9WVlZcR57MmqKTPsLDw7Fy5UqsXbsWiYmJGD16NLKzsxEWFgYACA0NRcRj6wUdOXIEcXFxuHz5Mvbt24euXbsiLy8P7zzWXTp58mT8+uuvuHLlCg4ePIjevXtDrVZjwIABJj+/J2k0wKBBwO3bgJ9ffqJoKkuWiGW6/v5bXExQZlKFsGCBeP3evcWw+LKyts5fWurjj0UNgrL4808xd9/KiktWFYeTE7Bhg/g9fPcd8N//yv8aaWmidxZgb3xF0749MGeOuP/WW8CFCwW3ycwUI0IePQJefz3/gikRERFReaRoIh8SEoKFCxdi1qxZaNWqFY4fP44dO3bA/X+LBicnJyM1NVW3/YMHDzBjxgw0bdoUvXv3Rq1atbB//364PDaO9/r16xgwYAAaNWqE119/HdWrV8fhw4fh5uZm6tMr4P33xRxiR0cx5NPGxrSvX7ly/uv++COwbJlpX1/r4kWR9AHyJmRDhgDPPCMSvpiYsh1Le5Glf3+gQYOyx1YRPP98/nSJCRPEqAs5LVoEPHggija++KK8xybz9+67QKdOYoWKAQOAx0c7SpIoipeUJEbPfP65cUaEEBEREZkLxYrdmTNjFMDZv198Cc3LE8NDBw+W5bClsnQpMH68SOgTEkR1Z1MaPlwk2t27A1u3ynvszz4T82i9vMQFg9JcLPnrr/xRAqdPA82ayRtjeZaXB3TrJubMt2ghhjrb25f9uBkZIkHLzhZ/M927l/2YZHmuXxf/X92+Dbz9NrBwoWhfvVr0wKvVwL594mJPecTibPLi+0lEROamJJ9NXE/BBP75Bxg4UCQ5Q4Yom8QDomJ+cLDo0QoJEcmRqVy9ml+syhjDo994A/D0FEXRnlYUqzDaXuU+fZjEl5SVFbB2rViN4dQpYMoUeY67ZIn4O33uOXGhgCqm2rXzR9ssWiTWmD93TvyfBgDz5pXfJJ6IiIjocUzkjUySgBEjRGJZv35+tXolqVTiy3DNmuJL8IQJpnvtjz4Sc1hfesk4X7jt7PKTx8hI8VolceGCmH4AcB52aXl45F9EWb5crNJQFnfuiMJlgPidcMh0xdazZ37iHhoq5sPfvy+mW0ydqmxsRERERKbCRN7IvvgCiIsDKlUSCeLT1kA2FVdX4KuvRFK0apVxipM96e+/xWsBxk2SR40S53f5cn5SXlwffCBGTvToATz7rHHiqwiCgsSqDIAYJXH9eumPtWwZkJUlRkf07ClPfGTZPv5YrBF/8yZw8qT4975unRhaT0RERFQRMJE3ort385dW++ADUanenLzwglh/HQBGjhRD/v/5x3ivt3AhkJMjKlB36mS816lcOX/5ufffF4l5cTw+7F/7vlDpvf8+0Lq1mM88aJBYtaGk7t0DPvlE3J8+XQzdJ7KzExfptPUXVq8WI4yIiIiIKgp+LTaiKlWAX38VheUmTlQ6GsPmzBG941ZWwNdfiwJlO3fK/zo3bwLR0eK+KYZHjxkDuLgAZ8/mr1f/NB9+aNxh/xWNjY1YncDRUazWUJrlFlesEBcCGjQQQ6iJtJo0AQ4eBPbsAV55ReloiIiIiEyLibyRNW8uCnWZa0+iWg3Mnw8cOCCSpZQUMSx6zBh5i+B98olY2711a3F8Y3Nyyp/7/957olZBUR4f9j9zpnFjq0jq1xfJOADMnStWbyiuf//Nr0r+7rscNk0FtWoFdO6sdBREREREpmem6SWZ2v/9H3D8eH4Rqc8+E1+SDx0q+7Fv385fs96UxcrGjxe9wSdPAj/9VPS2CxeKKv4dOgAdO5omvopi8GBRlCwvT6zeUNzpG//9L3DjBlCnjhiaT0REREREAhN50nFwEGvM79ollnm6eFEkttOniyS3tJYuFfUCWrQQy96ZSrVqYmQBIEYdFNYrf+OGaYf9V0TLlone+WvXxCoOTxshkZMjVjgAgGnTRLFIIiIiIiISmMhTAYGBYg3wIUNEL+qCBUCbNqKtpLKyxNQCIH8uvimFh4uCWL//Li5QGKId9v/888DLL5s2voqiShVRnKxSJbGKwxdfFL392rWi0n3NmkBYmGliJCIiIiKyFEzkySAXF1HBfdMmsbTTiRNifvtHH5Ws+vhnn4mh1I0aAX37Gi3cQtWoAfznP+L+e+8VfF6pYf8VkZ+fWL0BEMUfT582vN3Dh0BkpLj/zjuAra1JwiMiM7B8+XJ4e3vDzs4O/v7+SEhIKHTbzp07Q6VSFbj16NHDhBETEREpg4k8FalPH5FwBQeL4fVTp4ql4y5devq+2dnAokXivpLFyiZPFhXU9+0T1dMft3SpWOKsZUtWvjaFiROBrl2BBw+A/v3FSIgnbdgAXLkCuLmJZRGJqGKIjY1FeHg4Zs+ejWPHjsHX1xdBQUG4ceOGwe3j4uKQmpqqu50+fRpqtRr9+vUzceRERESmx0SensrdHfjhByAmRgyRPnAA8PUFPv+86LnOK1cCGRlA3brAgAGmi/dJtWoBb7wh7s+fn9+elQVERYn7XKPcNKysxLB5d3fgr7+At9/Wf16jyV+m7u23Rd0GIqoYFi9ejJEjRyIsLAxNmzZFdHQ0HBwcEBMTY3D7atWqwcPDQ3fbtWsXHBwcmMgTEVGFwNSFikWlEnOVT54UPfLZ2cCbbwLdu4ul25704EF+sbKICOWLlU2dClhbA7t3A4cPi7bPPgPu3AEaN1Zm2H9FVaMGsG6duL9ihZgzr7VxI3D+PFC1KvDWW8rER0Sml5ubi6NHjyIwMFDXZmVlhcDAQBwq5vIpq1atQv/+/VG5cmWDz+fk5CArK0vvRkREZKmYyFOJeHsDv/wiCsTZ2gI7dgDNm4tCZo9bvRpITRXV70NDFQlVj7e3KN4HiB5fcxn2X1F16SIurgDA8OFAcrIorKitYzBxohj9QUQVQ0ZGBjQaDdzd3fXa3d3dkZaW9tT9ExIScPr0aYwYMaLQbSIjI+Hs7Ky7eXl5lTluIiIipTCRpxKzshKJ1rFjooDZP/+IofP9+wO3boliZdqiZuZUrCwiQsT+009iWbqMDKBePWWH/Vdk8+eL1RDu3BFrzX//vajHUKUKMG6c0tERkSVZtWoVWrRogTZt2hS6TUREBDIzM3W3a9eumTBCIiIieTGRp1Jr2hQ4dAiYM0f0aMfGirXix40TPazu7mLNcHPRoIG42ACIedqASO6trZWLqSKrVEkUtqtSRRQi1I6YGDdODK0noorD1dUVarUa6enpeu3p6enw8PAoct/s7Gx88803GD58eJHb2drawsnJSe9GRERkqZjIU5lUqgTMni3mnTduLIbTf/65eG7yZLGGuzl59938++Yy7L8iq1cv/+/l339FcbuJExUNiYgUYGNjAz8/P8THx+va8vLyEB8fj7Zt2xa573fffYecnBwMHjzY2GESERGZDSbyJIvWrcVQe20S5ukpiuGZm2bN8nvlZ8wQy9KRsgYMEIUUAdEb7+ambDxEpIzw8HCsXLkSa9euRWJiIkaPHo3s7GyE/e8/iNDQUERERBTYb9WqVejVqxeqV69u6pCJiIgUw0HFJBt7e1EEb+xY0bPq6Kh0RIbFxIgLDkVMpSQTW7lSLBH4f/+ndCREpJSQkBDcvHkTs2bNQlpaGlq1aoUdO3boCuAlJyfD6ol1Qs+dO4f9+/dj586dSoRMRESkGJUkFbUSeMWUlZUFZ2dnZGZmcg4dERGZBX42yYvvJxERmZuSfDZxaD0RERERERGRBWEiT0RERERERGRBmMgTERERERERWRAm8kREREREREQWhIk8ERERERERkQVhIk9ERERERERkQZjIExEREREREVkQJvJEREREREREFoSJPBEREREREZEFYSJPREREREREZEGYyBMRERERERFZECbyRERERERERBbEWukAiIiIiCifRgPs2wekpgKenkBAAKBWKx0VERGZEybyRERERGYiLg6YMAG4fj2/rXZtYMkSoE8f5eIiIiLzwqH1RERERGYgLg547TX9JB4AUlJEe1ycMnEREZH5YSJPREREpDCNRvTES1LB57RtEyeK7YiIiJjIExERESls376CPfGPkyTg2jWxHRERERN5IiIiIoWlpsq7HRERlW9M5ImIiIgU5ukp73ZERFS+MZEnIiIiUlhAgKhOr1IZfl6lAry8xHZERERM5ImIiIgUplaLJeaAgsm89nFUFNeTJyIigYk8ERERkRno0wfYuBGoVUu/vXZt0c515ImISMta6QCIiIiISOjTB+jZU1SnT00Vc+IDAtgTT0RE+pjIExEREZkRtRro3FnpKIiIyJxxaD0RERERERGRBWEiT0RERERERGRBmMgTERERERERWRAm8kREREREREQWRPFEfvny5fD29oadnR38/f2RkJBQ6LYPHz7EvHnz4OPjAzs7O/j6+mLHjh1lOiYRERERERGRJVE0kY+NjUV4eDhmz56NY8eOwdfXF0FBQbhx44bB7WfMmIHPP/8cS5cuxZkzZ/Dmm2+id+/e+PPPP0t9TCIiIqLyTKMB9u4FNmwQPzUapSMiIqKyUkmSJCn14v7+/nj++eexbNkyAEBeXh68vLwwbtw4TJs2rcD2NWvWxPTp0zFmzBhdW9++fWFvb4+vvvqqVMc0JCsrC87OzsjMzISTk1NZT5OIiKjM+Nkkr4ryfsbFARMmANev57fVrg0sWSLWrCciIvNRks8mxXrkc3NzcfToUQQGBuYHY2WFwMBAHDp0yOA+OTk5sLOz02uzt7fH/v37S31M7XGzsrL0bkRERESWLC4OeO01/SQeAFJSRHtcnDJxERFR2SmWyGdkZECj0cDd3V2v3d3dHWlpaQb3CQoKwuLFi3HhwgXk5eVh165diIuLQ2pqaqmPCQCRkZFwdnbW3by8vMp4dkRERETK0WhET7yhcZfatokTOcyeiMhSKV7sriSWLFmCBg0aoHHjxrCxscHYsWMRFhYGK6uynUZERAQyMzN1t2vXrskUMREREZHp7dtXsCf+cZIEXLsmtiMiIsujWCLv6uoKtVqN9PR0vfb09HR4eHgY3MfNzQ2bN29GdnY2rl69irNnz8LR0RH16tUr9TEBwNbWFk5OTno3IiIiIkv1v8GKsm1HRETmRbFE3sbGBn5+foiPj9e15eXlIT4+Hm3bti1yXzs7O9SqVQuPHj3Cpk2b0LNnzzIfk4iIiKi88PSUdzsiIjIv1kq+eHh4OIYOHYrWrVujTZs2iIqKQnZ2NsLCwgAAoaGhqFWrFiIjIwEAR44cQUpKClq1aoWUlBTMmTMHeXl5eOedd4p9TCIiIqLyLiBAVKdPSTE8T16lEs8HBJg+NiIiKjtFE/mQkBDcvHkTs2bNQlpaGlq1aoUdO3boitUlJyfrzX9/8OABZsyYgcuXL8PR0RHdu3fHunXr4OLiUuxjEhEREZV3arVYYu6110TS/ngyr1KJn1FRYjsiIrI8iq4jb64qytqyRERkOfjZJK+K8n4aWkfey0sk8VxHnojIvJTks0nRHnkiIiIiMp4+fYCePUV1+tRUMSc+IIA98URElo6JPBEREVE5plYDnTsrHQUREcnJotaRJyIiIiIiIqromMgTERERERERWRAm8kREREREREQWhIk8ERERERERkQVhIk9ERERERERkQZjIExEREREREVkQJvJEREREREREFoSJPBEREREREZEFYSJPREREREREZEGYyBMRERERERFZECbyRERERERERBaEiTwRERERERGRBWEiT0RERIpbvnw5vL29YWdnB39/fyQkJBS5/Z07dzBmzBh4enrC1tYWDRs2xLZt20wULRERkbKslQ6AiIiIKrbY2FiEh4cjOjoa/v7+iIqKQlBQEM6dO4caNWoU2D43NxddunRBjRo1sHHjRtSqVQtXr16Fi4uL6YMnIiJSABN5IiIiUtTixYsxcuRIhIWFAQCio6OxdetWxMTEYNq0aQW2j4mJwe3bt3Hw4EFUqlQJAODt7V3ka+Tk5CAnJ0f3OCsrS74TICIiMjEOrSciIiLF5Obm4ujRowgMDNS1WVlZITAwEIcOHTK4z5YtW9C2bVuMGTMG7u7uaN68ORYsWACNRlPo60RGRsLZ2Vl38/Lykv1ciIiITIWJPBERESkmIyMDGo0G7u7ueu3u7u5IS0szuM/ly5exceNGaDQabNu2DTNnzsSiRYvw3nvvFfo6ERERyMzM1N2uXbsm63kQERGZEofWExERkUXJy8tDjRo18MUXX0CtVsPPzw8pKSn4+OOPMXv2bIP72NrawtbW1sSRlk8aDbBvH5CaCnh6AgEBgFqtdFRERBULE3kiIiJSjKurK9RqNdLT0/Xa09PT4eHhYXAfT09PVKpUCerHsscmTZogLS0Nubm5sLGxMWrMFVlcHDBhAnD9en5b7drAkiVAnz7KxUVEVNFwaD0REREpxsbGBn5+foiPj9e15eXlIT4+Hm3btjW4T/v27XHx4kXk5eXp2s6fPw9PT08m8UYUFwe89pp+Eg8AKSmiPS5OmbiIiCoiJvJERESkqPDwcKxcuRJr165FYmIiRo8ejezsbF0V+9DQUEREROi2Hz16NG7fvo0JEybg/Pnz2Lp1KxYsWIAxY8YodQrlnkYjeuIlqeBz2raJE8V2RERkfBxaT0RERIoKCQnBzZs3MWvWLKSlpaFVq1bYsWOHrgBecnIyrKzy+x68vLzw888/Y9KkSWjZsiVq1aqFCRMmYOrUqUqdQrm3b1/BnvjHSRJw7ZrYrnPnkh2bc+6JiEqOiTwREREpbuzYsRg7dqzB5/bu3VugrW3btjh8+LCRoyKt1FR5t9PinHsiotLh0HoiIiIiKpKnp7zbAZxzT0RUFkzkiYiIiKhIAQGip1ylMvy8SgV4eYntioNz7omIyoaJPBEREREVSa0Ww92Bgsm89nFUVPHntpdkzj0RERXERJ6IiIiInqpPH2DjRqBWLf322rVFe0nmtBtrzj0RUUXBYndEREREVCx9+gA9e5a9yrwx5twTEVUkTOSJiIiIqNjU6pIvMfck7Zz7lBTD8+RVKvF8cefcExFVNBxaT0REREQmJfeceyKiioaJPBERERGZnJxz7omIKhoOrSciIiIiRcg1597SaDQV75yJSF5M5ImIiIhIMXLMubckcXHAhAn6y+/Vri2mGnAUAhEVFxN5IiIiIipXzLXHOy4OeO21ggX+UlJEe2mnFJjr+RKR8XCOPBERERGVG3FxgLc38MILwMCB4qe3t2hXkkYjeuINVenXtk2cKLYrCXM9XyIyLibyRERERFQuaHu8Hx+2DuT3eCuZ3O7bVzCux0kScO2a2K64jHm+Gg2wdy+wYYP4WdILDERkXEzkiYiIiMjiGavHW3vssia1qanybmfM82UvP5H5YyJPRERERBbPGD3egHxJraenvNsZ83zNdVQDEeVjIk9EREREFk/uHm9A3qQ2IEBUp1epDD+vUgFeXmK74jDG+Rqzl5+I5MVEnoiIiIgsntw93nIntWq1WGIOKJjMax9HRRW/2rzc5wsYr5ffGDiHnyo6JvJEREREZPHk7vE2RlLbp49YYq5WLf322rVLvvSc3OcLGKeX3xg4h5+IiTwRERERlQNy93gbK6nt0we4cgXYswdYv178TEoq+frxcp8vYJxefi25etA5h59IYCJPREREROWCnD3exkxq1Wqgc2dgwADxsyTJ9uPkPF/AOL38gHw96JY0h59D/8nYVJJk6J9CxZaVlQVnZ2dkZmbCyclJ6XCIiIj42SQzvp/lm0YjhrynpopEOyCg5MmyRiOSzZQUw4mjSiWS3qSk0ificpHjfLW0Pd6A/nlrk/uSXiDQHu/J97A0x9u7V1wEeJo9e8QFEqXExYkLDo+PGqhdW4ygKOnFFapYSvLZxB55IiIiIipX5OjxNsbQdWORq4cfkLeXX+4edGPO4efQf7I0TOSJiIiIiAyQe+i6pZBrHr/cBQONNd2hIg79J8uneCK/fPlyeHt7w87ODv7+/khISChy+6ioKDRq1Aj29vbw8vLCpEmT8ODBA93zc+bMgUql0rs1btzY2KdBREREROWQXEmtpZGjl1/uHnRjzOGXswfd2Mv3cd49Pc5ayRePjY1FeHg4oqOj4e/vj6ioKAQFBeHcuXOoUaNGge3Xr1+PadOmISYmBu3atcP58+cxbNgwqFQqLF68WLdds2bNsHv3bt1ja2tFT5OIiIiILJg2qaWSkbsHXTvd4bXXRNJuaA5/SaY7PK0HXaUSPeg9exbvmMYc+s959/QkRXvkFy9ejJEjRyIsLAxNmzZFdHQ0HBwcEBMTY3D7gwcPon379hg4cCC8vb3x8ssvY8CAAQV68a2treHh4aG7ubq6muJ0iIiIiIjof4zRgy7ndAdLGvpvjHn37OG3bIol8rm5uTh69CgCAwPzg7GyQmBgIA4dOmRwn3bt2uHo0aO6xP3y5cvYtm0bunfvrrfdhQsXULNmTdSrVw+DBg1CcnJykbHk5OQgKytL70ZERERERKVnrIKBck13sISh/8aady9XXQBj4oWGoimWyGdkZECj0cDd3V2v3d3dHWlpaQb3GThwIObNm4cOHTqgUqVK8PHxQefOnfHuu+/qtvH398eaNWuwY8cOrFixAklJSQgICMDdu3cLjSUyMhLOzs66m5eXlzwnSURERERUgRmrYKAcc/iNNfQfkO/ChTHm3VtCZX1jXWgoTxcHFC92VxJ79+7FggUL8Nlnn+HYsWOIi4vD1q1bMX/+fN023bp1Q79+/dCyZUsEBQVh27ZtuHPnDr799ttCjxsREYHMzEzd7dq1a6Y4HSIiIiKics9cCwaa+9B/QP5RA8asrG/uS/hZwiiEklCsCpyrqyvUajXS09P12tPT0+Hh4WFwn5kzZ2LIkCEYMWIEAKBFixbIzs7GqFGjMH36dFhZFbwu4eLigoYNG+LixYuFxmJrawtbW9synA0RERERERXGHAsGyl08T6tPH1Egb98+kWB7eoqLAeYwaqAkPfwl+X3JVYxP7gKEj8f32msFj6u9OGCJy0kq1iNvY2MDPz8/xMfH69ry8vIQHx+Ptm3bGtzn/v37BZJ19f9+g5Kh3zaAe/fu4dKlS/AsaVUJIiIiIiIq18x56D8g/6gBY1TWN/cl/Iw5CkFJig6tDw8Px8qVK7F27VokJiZi9OjRyM7ORlhYGAAgNDQUERERuu2Dg4OxYsUKfPPNN0hKSsKuXbswc+ZMBAcH6xL6yZMn49dff8WVK1dw8OBB9O7dG2q1GgMGDFDkHImIiIiIyHyZ69B/QP5593L38MudJBvjQoMxLg6YA0UXWA8JCcHNmzcxa9YspKWloVWrVtixY4euAF5ycrJeD/yMGTOgUqkwY8YMpKSkwM3NDcHBwXj//fd121y/fh0DBgzArVu34Obmhg4dOuDw4cNwc3Mz+fkREREREZH5M8eh/1raUQOGhq5HRZXsgoO2hz8lxXDyrVKJ54vbwy/3UH1jLOFnjIsD5kAlFTYmvQLLysqCs7MzMjMz4eTkpHQ4RERE/GySGd9PIrI0Go088+61Q+EBw3UBSjKlYMMGUTjuadavF9MMnkajEQXonnahISmp+Oe+d68obPc0e/YofzGnJJ9NFlW1noiIiIiIqCKSa969nHUBLGEJP2OsTmAOmMgTERERERFVIHLVBbCEJfyMcXFAS8l16RWdI09ERERERESmJ0ddAEtYwk97PLnqDGjJteReaXGOvAGcN0dEROaGn03y4vtJRCQfQ0mtl1fpk2RjkbvOwJOZdGnqDDyuJJ9NTOQN4Ic7ERGZG342yYvvJxGRvORKks2dtiBfYdX6S1OQT6skn00cWk9ERERERERlYs5L+MlJ7iX3SovF7oiIiIiIiIiKwVzWpWciT0RERERERFQMci+5V1pM5ImIiIiIiIiKwVzWpWciT0RERERERFQMxlyXviSYyBMREREREREVk3Zd+lq19Ntr1y790nMlxar1RERERERERCXQpw/Qs6dyS+4xkSciIiIiIiIqISWX3OPQeiIiIiIiIiILwkSeiIiIiIiIyIIwkSciIiIiIiKyIEzkiYiIiIiIiCwIE3kiIiIiIiIiC8JEnoiIiMzC8uXL4e3tDTs7O/j7+yMhIaHQbdesWQOVSqV3s7OzM2G0REREymEiT0RERIqLjY1FeHg4Zs+ejWPHjsHX1xdBQUG4ceNGofs4OTkhNTVVd7t69aoJIyYiIlIOE3kiIiJS3OLFizFy5EiEhYWhadOmiI6OhoODA2JiYgrdR6VSwcPDQ3dzd3c3YcRERETKYSJPREREisrNzcXRo0cRGBioa7OyskJgYCAOHTpU6H737t1DnTp14OXlhZ49e+Kvv/4qdNucnBxkZWXp3YiIiCwVE3kiIiJSVEZGBjQaTYEedXd3d6SlpRncp1GjRoiJicEPP/yAr776Cnl5eWjXrh2uX79ucPvIyEg4Ozvrbl5eXrKfBxERkakwkSciIiKL07ZtW4SGhqJVq1bo1KkT4uLi4Obmhs8//9zg9hEREcjMzNTdrl27ZuKIiYiI5GOtdABERERUsbm6ukKtViM9PV2vPT09HR4eHsU6RqVKlfDss8/i4sWLBp+3tbWFra1tmWMlIiIyB6Xqkd+zZ4/ccRAREVEFZWNjAz8/P8THx+va8vLyEB8fj7Zt2xbrGBqNBqdOnYKnp6exwiQiIjIbpUrku3btCh8fH7z33nscmkZERERlFh4ejpUrV2Lt2rVITEzE6NGjkZ2djbCwMABAaGgoIiIidNvPmzcPO3fuxOXLl3Hs2DEMHjwYV69exYgRI5Q6BSIiIpMp1dD6lJQUrFu3DmvXrsXcuXPx4osvYvjw4ejVqxdsbGzkjpGIiIjKuZCQENy8eROzZs1CWloaWrVqhR07dugK4CUnJ8PKKr//4Z9//sHIkSORlpaGqlWrws/PDwcPHkTTpk2VOgUiIiKTUUmSJJXlAMeOHcPq1auxYcMGAMDAgQMxfPhw+Pr6yhKgErKysuDs7IzMzEw4OTkpHQ4RERE/m2TG95OIiMxNST6byly1/rnnnkNERATGjh2Le/fuISYmBn5+fggICChyPVciIiIiIiIiKrlSJ/IPHz7Exo0b0b17d9SpUwc///wzli1bhvT0dFy8eBF16tRBv3795IyViIiIiIiIqMIr1Rz5cePGYcOGDZAkCUOGDMFHH32E5s2b656vXLkyFi5ciJo1a8oWKBERERERERGVMpE/c+YMli5dij59+hS6JqurqyuXqSMiIiIiIiKSWakS+cfXeS30wNbW6NSpU2kOT0RERERERESFKNUc+cjISMTExBRoj4mJwYcffljmoIiIiIiIiIjIsFIl8p9//jkaN25coL1Zs2aIjo4uc1BEREREREREZFipEvm0tDR4enoWaHdzc0NqamqZgyIiIiIiIiIiw0qVyHt5eeHAgQMF2g8cOMBK9URERERERERGVKpidyNHjsTEiRPx8OFDvPjiiwBEAbx33nkHb7/9tqwBEhEREREREVG+UiXyU6ZMwa1bt/DWW28hNzcXAGBnZ4epU6ciIiJC1gCJiIiIiIiIKF+pEnmVSoUPP/wQM2fORGJiIuzt7dGgQYNC15QnIiIiIiIiInmUKpHXcnR0xPPPPy9XLERERERERET0FKVO5P/44w98++23SE5O1g2v14qLiytzYERERERERERUUKmq1n/zzTdo164dEhMT8f333+Phw4f466+/8Msvv8DZ2VnuGImIiIiIiIjof0qVyC9YsACffPIJfvzxR9jY2GDJkiU4e/YsXn/9dTzzzDNyx0hERERERERE/1OqRP7SpUvo0aMHAMDGxgbZ2dlQqVSYNGkSvvjiC1kDJCIiIvO0du1abN26Vff4nXfegYuLC9q1a4erV68qGBkREVH5VqpEvmrVqrh79y4AoFatWjh9+jQA4M6dO7h//7580REREZHZWrBgAezt7QEAhw4dwvLly/HRRx/B1dUVkyZNUjg6IiKi8qtUxe46duyIXbt2oUWLFujXrx8mTJiAX375Bbt27cJLL70kd4xERERkhq5du4b69esDADZv3oy+ffti1KhRaN++PTp37qxscEREROVYqXrkly1bhv79+wMApk+fjvDwcKSnp6Nv375YtWpViY61fPlyeHt7w87ODv7+/khISChy+6ioKDRq1Aj29vbw8vLCpEmT8ODBgzIdk4iIiErO0dERt27dAgDs3LkTXbp0AQDY2dnh33//VTI0IiKicq3EPfKPHj3CTz/9hKCgIACAlZUVpk2bVqoXj42NRXh4OKKjo+Hv74+oqCgEBQXh3LlzqFGjRoHt169fj2nTpiEmJgbt2rXD+fPnMWzYMKhUKixevLhUxyQiIqLS6dKlC0aMGIFnn30W58+fR/fu3QEAf/31F7y9vZUNjoiIqBwrcY+8tbU13nzzzQK94KWxePFijBw5EmFhYWjatCmio6Ph4OCAmJgYg9sfPHgQ7du3x8CBA+Ht7Y2XX34ZAwYM0OtxL+kxiYiIqHSWL1+Otm3b4ubNm9i0aROqV68OADh69CgGDBigcHRERETlV6nmyLdp0wbHjx9HnTp1Sv3Cubm5OHr0KCIiInRtVlZWCAwMxKFDhwzu065dO3z11VdISEhAmzZtcPnyZWzbtg1Dhgwp9TEBICcnBzk5ObrHWVlZpT4vIiKiisLFxQXLli0r0D537lwFoiEiIqo4SpXIv/XWWwgPD8e1a9fg5+eHypUr6z3fsmXLpx4jIyMDGo0G7u7ueu3u7u44e/aswX0GDhyIjIwMdOjQAZIk4dGjR3jzzTfx7rvvlvqYABAZGckvHURERCW0Y8cOODo6okOHDgBED/3KlSvRtGlTLF++HFWrVlU4QiIiovKpVMXu+vfvj6SkJIwfPx7t27dHq1at8Oyzz+p+GsvevXuxYMECfPbZZzh27Bji4uKwdetWzJ8/v0zHjYiIQGZmpu527do1mSImIiIqv6ZMmaIbxXbq1Cm8/fbb6N69O5KSkhAeHq5wdEREROVXqXrkk5KSyvzCrq6uUKvVSE9P12tPT0+Hh4eHwX1mzpyJIUOGYMSIEQCAFi1aIDs7G6NGjcL06dNLdUwAsLW1ha2tbRnPiIiIqGJJSkpC06ZNAQCbNm3CK6+8ggULFuDYsWO6wndEREQkv1L1yNepU6fIW3HY2NjAz88P8fHxura8vDzEx8ejbdu2Bve5f/8+rKz0Q1ar1QAASZJKdUwiIiIqHRsbG9y/fx8AsHv3brz88ssAgGrVqrHeDBERkRGVqkf+yy+/LPL50NDQYh0nPDwcQ4cORevWrdGmTRtERUUhOzsbYWFhuuPUqlULkZGRAIDg4GAsXrwYzz77LPz9/XHx4kXMnDkTwcHBuoT+acckIiIieXTo0AHh4eFo3749EhISEBsbCwA4f/48ateurXB0RERE5VepEvkJEyboPX748CHu378PGxsbODg4FDuRDwkJwc2bNzFr1iykpaWhVatW2LFjh65YXXJysl4P/IwZM6BSqTBjxgykpKTAzc0NwcHBeP/994t9TCIiIpLHsmXL8NZbb2Hjxo1YsWIFatWqBQDYvn07unbtqnB0RERE5ZdKkiRJjgNduHABo0ePxpQpUxAUFCTHIRWTlZUFZ2dnZGZmwsnJSelwiIiI+NkkM76fRERkbkry2VSqHnlDGjRogA8++ACDBw8ucqk3IiIiKj80Gg02b96MxMREAECzZs3w6quv6qa8ERERkfxkS+QBwNraGn///bechyQiIiIzdfHiRXTv3h0pKSlo1KgRACAyMhJeXl7YunUrfHx8FI6QiIiofCpVIr9lyxa9x5IkITU1FcuWLUP79u1lCYyIiIjM2/jx4+Hj44PDhw+jWrVqAIBbt25h8ODBGD9+PLZu3apwhEREROVTqRL5Xr166T1WqVRwc3PDiy++iEWLFskRFxEREZm5X3/9VS+JB4Dq1avjgw8+4IV9IiIiIypVIp+Xlyd3HERERGRhbG1tcffu3QLt9+7dg42NjQIRERERVQxWT9+EiIiIqKBXXnkFo0aNwpEjRyBJEiRJwuHDh/Hmm2/i1VdfVTo8IiKicqtUiXzfvn3x4YcfFmj/6KOP0K9fvzIHRURERObv008/hY+PD9q2bQs7OzvY2dmhXbt2qF+/PqKiopQOj4iIqNwq1dD63377DXPmzCnQ3q1bN86RJyIiqiBcXFzwww8/4OLFi7rl55o0aYL69esrHBkREVH5VqpEvrC5b5UqVUJWVlaZgyIiIiLzFB4eXuTze/bs0d1fvHixscMhIiKqkEqVyLdo0QKxsbGYNWuWXvs333yDpk2byhIYERERmZ8///yzWNupVCojR0JERFRxlSqRnzlzJvr06YNLly7hxRdfBADEx8djw4YN+O6772QNkIiIiMzH4z3uREREpIxSJfLBwcHYvHkzFixYgI0bN8Le3h4tW7bE7t270alTJ7ljJCIiIiIiIqL/KVUiDwA9evRAjx495IyFiIiIiIiIiJ6iVMvP/f777zhy5EiB9iNHjuCPP/4oc1BEREREREREZFipEvkxY8bg2rVrBdpTUlIwZsyYMgdFRERERERERIaVKpE/c+YMnnvuuQLtzz77LM6cOVPmoIiIiIiIiIjIsFIl8ra2tkhPTy/QnpqaCmvrUk+7JyIiIiIiIqKnKFUi//LLLyMiIgKZmZm6tjt37uDdd99Fly5dZAuOiIiIiIiIiPSVqvt84cKF6NixI+rUqYNnn30WAHD8+HG4u7tj3bp1sgZIRERERERERPlKlcjXqlULJ0+exNdff40TJ07A3t4eYWFhGDBgACpVqiR3jERERERERET0P6We0F65cmV06NABzzzzDHJzcwEA27dvBwC8+uqr8kRHRERERERERHpKlchfvnwZvXv3xqlTp6BSqSBJElQqle55jUYjW4BERERERERElK9Uxe4mTJiAunXr4saNG3BwcMDp06fx66+/onXr1ti7d6/MIRIRERERERGRVqkS+UOHDmHevHlwdXWFlZUV1Go1OnTogMjISIwfP17uGImIiKgCWL58Oby9vWFnZwd/f38kJCQUa79vvvkGKpUKvXr1Mm6AREREZqJUibxGo0GVKlUAAK6urvj7778BAHXq1MG5c+fki46IiIgqhNjYWISHh2P27Nk4duwYfH19ERQUhBs3bhS535UrVzB58mQEBASYKFIiIiLllSqRb968OU6cOAEA8Pf3x0cffYQDBw5g3rx5qFevnqwBEhERUfm3ePFijBw5EmFhYWjatCmio6Ph4OCAmJiYQvfRaDQYNGgQ5s6dy+8fRERUoZQqkZ8xYwby8vIAAPPmzUNSUhICAgKwbds2fPrpp7IGSEREROVbbm4ujh49isDAQF2blZUVAgMDcejQoUL3mzdvHmrUqIHhw4c/9TVycnKQlZWldyMiIrJUpapaHxQUpLtfv359nD17Frdv30bVqlX1qtcTERERPU1GRgY0Gg3c3d312t3d3XH27FmD++zfvx+rVq3C8ePHi/UakZGRmDt3bllDJSIiMgul6pE3pFq1akziiYiIyOju3r2LIUOGYOXKlXB1dS3WPhEREcjMzNTdrl27ZuQoiYiIjKdUPfJEREREcnF1dYVarUZ6erpee3p6Ojw8PApsf+nSJVy5cgXBwcG6Nu2UP2tra5w7dw4+Pj56+9ja2sLW1tYI0RMREZmebD3yRERERKVhY2MDPz8/xMfH69ry8vIQHx+Ptm3bFti+cePGOHXqFI4fP667vfrqq3jhhRdw/PhxeHl5mTJ8IiIik2OPPBERESkuPDwcQ4cORevWrdGmTRtERUUhOzsbYWFhAIDQ0FDUqlULkZGRsLOzQ/PmzfX2d3FxAYAC7UREROURE3kiIiJSXEhICG7evIlZs2YhLS0NrVq1wo4dO3QF8JKTk2FlxYGEREREAKCSJElSOghzk5WVBWdnZ2RmZsLJyUnpcIiIiPjZJDO+n0REZG5K8tnES9tEREREREREFoSJPBEREREREZEFYSJPREREREREZEGYyBMRERERERFZECbyRERERERERBaEiTwRERERERGRBWEiT0RERERERGRBmMgTERERERERWRAm8kREREREREQWhIk8ERERERERkQVhIk9ERERERERkQZjIExEREREREVkQJvJEREREREREFoSJPBEREREREZEFMYtEfvny5fD29oadnR38/f2RkJBQ6LadO3eGSqUqcOvRo4dum2HDhhV4vmvXrqY4FSIiIiIiIiKjslY6gNjYWISHhyM6Ohr+/v6IiopCUFAQzp07hxo1ahTYPi4uDrm5ubrHt27dgq+vL/r166e3XdeuXbF69WrdY1tbW+OdBBEREREREZGJKN4jv3jxYowcORJhYWFo2rQpoqOj4eDggJiYGIPbV6tWDR4eHrrbrl274ODgUCCRt7W11duuatWqpjgdIiIiIiIiIqNSNJHPzc3F0aNHERgYqGuzsrJCYGAgDh06VKxjrFq1Cv3790flypX12vfu3YsaNWqgUaNGGD16NG7dulXoMXJycpCVlaV3IyIiIiIiIjJHiibyGRkZ0Gg0cHd312t3d3dHWlraU/dPSEjA6dOnMWLECL32rl274ssvv0R8fDw+/PBD/Prrr+jWrRs0Go3B40RGRsLZ2Vl38/LyKv1JERERERERERmR4nPky2LVqlVo0aIF2rRpo9fev39/3f0WLVqgZcuW8PHxwd69e/HSSy8VOE5ERATCw8N1j7OyspjMExERERERkVlStEfe1dUVarUa6enpeu3p6enw8PAoct/s7Gx88803GD58+FNfp169enB1dcXFixcNPm9rawsnJye9GxEREREREZE5UjSRt7GxgZ+fH+Lj43VteXl5iI+PR9u2bYvc97vvvkNOTg4GDx781Ne5fv06bt26BU9PzzLHTERERERERKQkxavWh4eHY+XKlVi7di0SExMxevRoZGdnIywsDAAQGhqKiIiIAvutWrUKvXr1QvXq1fXa7927hylTpuDw4cO4cuUK4uPj0bNnT9SvXx9BQUEmOSciIiIiIiIiY1F8jnxISAhu3ryJWbNmIS0tDa1atcKOHTt0BfCSk5NhZaV/veHcuXPYv38/du7cWeB4arUaJ0+exNq1a3Hnzh3UrFkTL7/8MubPn8+15ImIiIiIiMjiqSRJkpQOwtxkZWXB2dkZmZmZnC9PRERmgZ9N8uL7SURE5qYkn02KD60nIiIiIiIiouJjIk9ERERERERkQZjIExEREREREVkQJvJEREREREREFoSJPBEREREREZEFYSJPREREREREZEGYyBMRERERERFZECbyRERERERERBaEiTwRERERERGRBWEiT0RERERERGRBmMgTERERERERWRAm8kREREREREQWhIk8ERERERERkQVhIk9ERERERERkQZjIExEREREREVkQJvJEREREREREFoSJPBEREREREZEFYSJPREREREREZEGYyBMRERERERFZECbyRERERERERBbEWukAiIiIyiONBti3D0hNBTw9gYAAQK1WOioiIiIqD5jIExERySwuDpgwAbh+Pb+tdm1gyRKgTx/l4iIiIqLygUPriYiIZBQXB7z2mn4SDwApKaI9Lk6ZuIiIiKj8YCJPRERGp9EAe/cCGzaInxqN0hEZh0YjeuIlqeBz2raJE8vv+RMREZFpMJEnIiKjiosDvL2BF14ABg4UP729y2fP9L59BXviHydJwLVrYjsiIiKi0mIiT0RERlPRhpmnpsq7HREREZEhTOSJiMgoKuIwc09PebcjIiIiMoSJPBERFSDHnHZLGmYu1xz+gABRnV6lMvy8SgV4eYntiIiIiEqLiTwREemRa067pQwzl3MOv1otlpgDCibz2sdRUVxPvjDLly+Ht7c37Ozs4O/vj4SEhEK3jYuLQ+vWreHi4oLKlSujVatWWLdunQmjJSIiUg4TeSIi0pFzTrslDDM3xhz+Pn2AjRuBWrX022vXFu1cR96w2NhYhIeHY/bs2Th27Bh8fX0RFBSEGzduGNy+WrVqmD59Og4dOoSTJ08iLCwMYWFh+Pnnn00cORERkempJMnQ7MWKLSsrC87OzsjMzISTk5PS4RARmYRGI3qiCxsOr1KJZDQpqXg9ytrjpaQYnidf0uPJTe7zNXT8ffvEiANPTzGcviznWd4/m/z9/fH8889j2bJlAIC8vDx4eXlh3LhxmDZtWrGO8dxzz6FHjx6YP3/+U7ct7+8nERFZnpJ8NrFHnoiIAMg/p93ch5kbew6/Wg107gwMGCB+cjh94XJzc3H06FEEBgbq2qysrBAYGIhDhw49dX9JkhAfH49z586hY8eOBrfJyclBVlaW3o2IiMhSMZEnIsXJVWjMUpjr+RpjTrs5DzO3lDn8FUFGRgY0Gg3c3d312t3d3ZGWllbofpmZmXB0dISNjQ169OiBpUuXokuXLga3jYyMhLOzs+7m5eUl6zkQERGZkrXSARBRxRYXJ5Yoe7xntHZt0ZNbHucSm/P5GmtOe58+QM+e8g4zl4MlzOGnolWpUgXHjx/HvXv3EB8fj/DwcNSrVw+dO3cusG1ERATCw8N1j7OyspjMExGRxWIiT0SK0RYae3L+tLbQWGl7bOWemywXY52vXLRLpz1tTntplk7TDjM3J8Y8XyoZV1dXqNVqpKen67Wnp6fDw8Oj0P2srKxQv359AECrVq2QmJiIyMhIg4m8ra0tbG1tZY2biIhIKRxaT0SK0GhEz7ShBErbNnFiyYedy7mUmJyMdb5yMvc57XKraOdrzmxsbODn54f4+HhdW15eHuLj49G2bdtiHycvLw85OTnGCJGIiMisMJEnIkUYo9CYMZYSA+SZ027swmpyMec57cZQ0c7XnIWHh2PlypVYu3YtEhMTMXr0aGRnZyMsLAwAEBoaioiICN32kZGR2LVrFy5fvozExEQsWrQI69atw+DBg5U6BSIiIpPh0HqiMjLXYdzmTu5CY0/r8VapRI93z54l+/3INafdmIXV5P4bNNc57cZS0c7XXIWEhODmzZuYNWsW0tLS0KpVK+zYsUNXAC85ORlWVvn9D9nZ2Xjrrbdw/fp12Nvbo3Hjxvjqq68QEhKi1CkQERGZDNeRN4Bry1JxmXPhMnO3d68Y9v40e/YUb2613McDCp/Trh12XZIeW2PEp42Rf4MVAz+b5MX3k4iIzA3XkScyAWMN464otIXGnpybrKVSAV5exS80ZuoefqBkc9rlPl+Af4NEREREFRUTeaJSsITCZeZO7kJjci8lJvecdrnPl3+DRERERBUXE3miUrCUwmXmTs5CY+beww/Ie74V/W9QjgKERERERJaKxe6ISsGYhcsqGrkKjWl7vF97TSTtj/dUm0MPv5Zc51uR/wZZF4CIiIgqOibyRKVgrCSvolKrS1bgrTDaHm9DSV5UVOl6+FNSDA9fV6nE8yWZ064lx/lW1L/BwgoQausCcMk4IiIiqghYtd4AVrKlp9FoAG/vpyd5SUlcwkoJci3Hpk0aAcM9/EomjRXxb1B7zoVNKSiP5/w4fjbJi+8nERGZG1atJzIyuQuXkby0Pd4DBoifpf09yDmnXW4V8W+wotcFICIiItJiIk9USuac5JF8+vQBrlwR67uvXy9+JiWZx++3ov0NVuS6AERERESP4xx5ojKQq3AZmTe55vAbQ0X6G6yodQGIiIiInmQWPfLLly+Ht7c37Ozs4O/vj4SEhEK37dy5M1QqVYFbjx49dNtIkoRZs2bB09MT9vb2CAwMxIULF0xxKlQByTWMW4vLalFJyf03aK7kXmKQiIiIyFIpnsjHxsYiPDwcs2fPxrFjx+Dr64ugoCDcuHHD4PZxcXFITU3V3U6fPg21Wo1+/frptvnoo4/w6aefIjo6GkeOHEHlypURFBSEBw8emOq0iEolLk4U83rhBWDgQPHT21u0E1V0FbEuABEREZEhiifyixcvxsiRIxEWFoamTZsiOjoaDg4OiImJMbh9tWrV4OHhobvt2rULDg4OukRekiRERUVhxowZ6NmzJ1q2bIkvv/wSf//9NzZv3mzCMyMqGW2F9CeLeWmX1SptMs8efipPKlpdACIiIiJDFE3kc3NzcfToUQQGBurarKysEBgYiEOHDhXrGKtWrUL//v1RuXJlAEBSUhLS0tL0juns7Ax/f/9Cj5mTk4OsrCy9G5EpaTRi7XNDy4hp2yZOLHkSzh5+Ko/MuQAhERERkSkomshnZGRAo9HA3d1dr93d3R1paWlP3T8hIQGnT5/GiBEjdG3a/UpyzMjISDg7O+tuXl5eJT0VojIxxrJaxurhJzIHFaUuABEREZEhig+tL4tVq1ahRYsWaNOmTZmOExERgczMTN3t2rVrMkVIVDxyL6tlrB5+IiIiIiJSnqKJvKurK9RqNdLT0/Xa09PT4eHhUeS+2dnZ+OabbzB8+HC9du1+JTmmra0tnJyc9G5UPpnrfHG5l9UyRg+/lrm+h0REREREFYWiibyNjQ38/PwQHx+va8vLy0N8fDzatm1b5L7fffcdcnJyMHjwYL32unXrwsPDQ++YWVlZOHLkyFOPSeWbOc8Xl3tZLbl7+LXM+T0kIiIiIqooFB9aHx4ejpUrV2Lt2rVITEzE6NGjkZ2djbCwMABAaGgoIiIiCuy3atUq9OrVC9WrV9drV6lUmDhxIt577z1s2bIFp06dQmhoKGrWrIlevXqZ4pTIDJn7fHG5l9WSu4cfMP/3kIiIiIioorBWOoCQkBDcvHkTs2bNQlpaGlq1aoUdO3boitUlJyfDykr/esO5c+ewf/9+7Ny50+Ax33nnHWRnZ2PUqFG4c+cOOnTogB07dsDOzs7o50Pm52nzxVUqMV+8Z09lC2Zpl9WaMEE/Wa5dWyTxJanIre3hT0kxfN4qlXi+uD38lvIeEhERERFVBCpJMvTVvGLLysqCs7MzMjMzOV++HNi7VwwBf5o9e0T1a6VpNGLuemqq6DEPCChdcqztQQf0E3BtD39J1ty2tPeQqDziZ5O8+H4SEZG5Kclnk+I98kRFkSOpNdZ8cWPRLqtVVnL28Fvae0hEREREVJ4xkSezFRdnOAldsqRkSagx5otbij59xHD3sl4MqcjvIRERERGRuWEiT2ZJOyz8yYkf2sJqJRkWLvd8cUsjRw9/RX8PiYiIiIjMieJV64me9LTCaoAorFbc9cvlrghfEfE9JCIiIiIyH0zkSVYajSiMtmGD+FncZPtx+/YVXOLscZIEXLsmtisu7XzxWrX022vXLlnvfkXG95CIiIiIyDxwaD3JRq457cYqrCbXfPGKjO8hEREREZHymMiTLOSc027MwmpyVYSvyPgeEhEREREpi0PrqczkntOuLaz25FxsLZUK8PJiYTUiIiIiIqqYmMhTmck9p52F1YiIiIiIiArHRJ7KzBhz2llYjYiIiIiIyDDOkacyM9acdhZWIyIiIiIiKog98lRmxpzTri2sNmCA+MkknoiIiIioYvj8c6BhQ+DMGaUjMT9M5KnMOKediIiIiIjkdPWqKJh94YJI6EkfE3mSBee0ExERERGRXN55B3jwQNz/6SfDK2RVZJwjT7LhnHYiIiIiIiqrX38Fvv0WsLISucTly8C5c0DjxkpHZj6YyJOstHPaiYiIiIiISkqjASZMEPf/8x/g0iVg507RK89EPh+H1hMREREREZFZWLUKOHECcHEB5s0DXnlFtG/dqmhYZoeJPBERERERESnun3+A6dPF/XnzAFdXoEcP8XjfPuDOHcVCMztM5ImIiIiIiEhx8+YBGRlA06bAm2+Ktnr1gCZNxJD7n39WNj5zwkSeiIiIiIiIFJWYCCxbJu4vWQJUqpT/HIfXF8REnoiIiIiIiBQjSWLN+EePxCpYgYH6z2uH12/bJnrmiYk8ERERERERKWjrVlGZ3sYGWLSo4PPt2onid7duAUeOmDw8s8REnoiIiIiIiBSRkwNMmiTuh4cDPj4Ft6lUCejaVdzn8HqBiTwREREREREp4tNPgYsXAU9P4N13C99OO7z+p59ME5e5YyJPREREREREJpeWBsyfL+5/8AFQpUrh23btClhZASdPAsnJponPnDGRr+A0GmDvXmDDBvGTxSOIiIiIiMgU3n0XuHsXaNMGGDy46G1dXYG2bcX9bduMH5u5YyJfgcXFAd7ewAsvAAMHip/e3qKdiIiIqDB5ebz4T0Rl8/vvwOrV4v6nn4re9qfh8Pp8TOQrqLg44LXXgOvX9dtTUkQ7k3kiIqLiOX5cXAw/cULpSExDkoA+fQA3N+DqVaWjISJLJEnA+PHifmgo4O9fvP2068nHxwP37xsnNkvBRL4C0miACRPEP6AnadsmTuSVdiIiouL48EMxPW3cOMOfreXN5s3ADz8A//wDrFypdDREZInWrwcOHwYqVwYiI4u/X/PmgJcX8OABsGeP8eKzBEzkK6B9+wr2xD9OkoBr18R2REREVLSPPgLs7cXnZmys0tEYV24uMGVK/uO1a3nhn4hK5t494J13xP0ZM4CaNYu/r0qV3ytf0YfXM5GvgFJT5d2OiIioIvPyyl8yafJk8SW1vFq2DLh0CXB3B6pWFR0Dv/yidFREZEk++AD4+2+gXj0xCriktIn81q0VYxRUYZjIV0CenvJuR0REVNFNniy+lKakAAsWKB2NcWRkAPPmifvvvw8MGCDua4tVERE9zeXLwMKF4v6iRYCdXcmP8cILYhTUtWvAqVPyxmdJmMhbELmWigsIAGrXFkNTDFGpRO9CQEBpIyUiIqpY7OyATz4R9xctAi5eVDYeY5g3D8jMBFq2BIYNA8LCRPv33wN37igZGRFZiilTgJwcIDAQ6NmzdMewtwdeekncr8jD65nIWwg5l4pTq4ElS8T9J5N57eOoKLEdERGRqSxfvhze3t6ws7ODv78/EhISCt125cqVCAgIQNWqVVG1alUEBgYWub0pBAcDQUFiHvmkSYqGIruzZ4HPPhP3Fy8W3xH8/IBmzUTRqfJeG4CIyu6XX0TuolaLXKOwTsXieHx4fUXFRN4CGGOpuD59gI0bgVq19Ntr1xbtffqUPl4iIqKSio2NRXh4OGbPno1jx47B19cXQUFBuHHjhsHt9+7diwEDBmDPnj04dOgQvLy88PLLLyMlJcXEkedTqcSF8kqVRC/Rtm2KhSK7KVPESMDg4PyeMJUqv1eew+uJqCiPHolVswDgrbfERcCy6N5d/Dx0SEz7qYhUklSRSwQYlpWVBWdnZ2RmZsLJyUnRWDQa0fNeWJV5lUok30lJpetB12hEld3UVDEnPiCAPfFERObInD6bjMHf3x/PP/88li1bBgDIy8uDl5cXxo0bh2nTpj11f41Gg6pVq2LZsmUIDQ0t8HxOTg5ycnJ0j7OysuDl5WWU9/Odd4CPPwbq1wdOnwZsbWU9vMnt3g106QJYW4vzadQo/7n0dNEpoNEAZ84ATZooFycRma/PPgPGjAGqVQMuXBA/y6pVK+DECeDLL4EhQ8p+PHNQks969sibOWMvFadWA507i4I1nTsziSciItPLzc3F0aNHERgYqGuzsrJCYGAgDh06VKxj3L9/Hw8fPkS1Qr4dRkZGwtnZWXfz8vKSJXZDZs4EPDzEPPmoKKO9jEloNEB4uLj/1lv6STwgqtdre8bWrDFpaERkIW7fFv8vAsD8+fIk8QCH1zORN3NcKo6IiMq7jIwMaDQauLu767W7u7sjLS2tWMeYOnUqatasqXcx4HERERHIzMzU3a5du1bmuAtTpYpYWx4QX1oVHO1fZqtXi6rQLi7ArFmGt9EOr1+3TgyfJSJ63OzZIplv0QIYNUq+4/boIX7u2AE8fCjfcS0FE3kzx6XiiIiIivbBBx/gm2++wffffw+7QtYysrW1hZOTk97NmAYPBtq1A7KzxVB7S3T3LjBjhrg/axZQvbrh7Xr0AFxdRafCzp2mi68oaWnAoEFc455IaadPAytWiPtLlogpOnJp00b835OZCRw8KN9xLQUTeTPHpeKIiKi8c3V1hVqtRnp6ul57eno6PDw8itx34cKF+OCDD7Bz5060bNnSmGGWiEoFLF0qfq5fX/opcEr64AMxB75+fTG3tTA2NiJpBsyn6N2MGeJ9HzUKyMtTOhqiikmSRIE7jQbo21esuiUntRro1k3cr4jL0DGRN3NcKo6IiMo7Gxsb+Pn5IT4+XteWl5eH+Ph4tG3bttD9PvroI8yfPx87duxA69atTRFqiTz3HDBypLg/bpz4Mmsprl4FFi0S9z/+WCTrRdEOr9+yBbh1y7ixPc21a6L4FQBcugRs365sPEQV1ebNYlSMra34f8QYtPPkmciTWeJScUREVN6Fh4dj5cqVWLt2LRITEzF69GhkZ2cj7H8ZYmhoKCIiInTbf/jhh5g5cyZiYmLg7e2NtLQ0pKWl4d69e0qdgkHvvw9UrSoqK3/xhdLRFF9EBJCTA3TqBPTs+fTtfX1FBencXGDDBqOHV6SFC8V8Wav/fcv99FNl4yGqiB48AN5+W9yfPBmoW9c4r/Pyy2K4/tmz4sJdRcJE3kL06QNcuQLs2SOGiu3ZI5acYxJPRETlQUhICBYuXIhZs2ahVatWOH78OHbs2KErgJecnIzUxyq7rlixArm5uXjttdfg6empuy1cuFCpUzDI1VUUvAPEcG+le6uL4/BhkYyrVMDixYVP73uSOawpf+MGsHKluB8dLWLfuRM4d065mIgqok8+EblKrVriwqCxuLgAHTqI+xWtej3XkTegvK/VS0REloefTfIy5fv56BHg5wecPAm8+WZ+4SdzJElA+/bAoUPAsGElS8ozMoCaNUVv+IkTgBIlC959F4iMFEWwDh8GXn1VDLkdO1bULCAi40tJEUtVZmcDX32VX0PDWBYtEr3+XbqYT8HN0uI68kRERERmwto6f3j3558Df/6pbDxF+fZbkcQ7OIhpASXh6goEB4v7Sqwpf+cOsHy5uD99uuiNHz8+P56sLNPHRFQRRUSIJL5dO2DgQOO/nnae/K+/itU2Kgom8kRERERG1qkT0L+/6PEeP178NDcPHgBTp4r7U6eK3vWS0g6v/+or06/rvGyZSNabN8//Yh8YCDRuDNy7B6xda9p4iCqiw4eBdevE/SVLij81pywaNgR8fESNjt27jf965oKJPBEREZEJfPyx6Onev1/UuzE3S5aIavW1auUXqSqprl0Bd3fg5k1g2zZ54ytKdrZYxQcQw+u1he5UKjGsHhCJPpeiIzKe27fzV+oICwNMtZiISlUxq9czkSciIiIygdq1xZBvAJgyxbyGgKan5w+lX7AAqFy5dMextgaGDBH3TVn07osvRCFBHx+gXz/950JDgSpVgPPnLX/+LJG5unlTrBN/+jTg5ib+HzGlHj3Ez23bKs4FO8UT+eXLl8Pb2xt2dnbw9/dHQkJCkdvfuXMHY8aMgaenJ2xtbdGwYUNse+yS75w5c6BSqfRujRs3NvZpEBERET3V22+LZDM1teRz0I1p9mxxYcHPDxg8uGzHGjZM/Ny6VVSRN7acHLHkHABMmyYuJjyuSpX8If8seEckv7Q0oHNnUdDTwwPYu1f8NKWOHQFHRxHLsWOmfW2lKJrIx8bGIjw8HLNnz8axY8fg6+uLoKAg3Cjkf/3c3Fx06dIFV65cwcaNG3Hu3DmsXLkStZ5YYL1Zs2ZITU3V3fbv32+K0yEiIiIqkq1t/hDwxYtFL7HSTp3KX7Ltk0/yh6WXVrNmwPPPi2r9X39d9vieZu1a4O+/xZQA7WiAJ2mH12/fDly8aPyYiCqKlBRRA+TMGfFv8NdfgaZNTR+Hra1YUx6oOMvQKZrIL168GCNHjkRYWBiaNm2K6OhoODg4ICYmxuD2MTExuH37NjZv3oz27dvD29sbnTp1gq+vr9521tbW8PDw0N1cXV1NcTpERERET9WjB9CtmygGN3GisoXvJEmMEsjLA/r2BQIC5Dnu42vKG/P8Hj0CPvxQ3J8yRXyZN6RBA/GeS1J+ZXsqWm6uSIjOnjXP4oykvKtXRU/4+fPAM8+IJL5hQ+Xi0Q6vryjz5BVL5HNzc3H06FEEBgbmB2NlhcDAQBw6dMjgPlu2bEHbtm0xZswYuLu7o3nz5liwYAE0Go3edhcuXEDNmjVRr149DBo0CMnJyUXGkpOTg6ysLL0bERERkTGoVKJXvlIl0UOs5JfOHTuAXbtELNqEWA79+4uk+tQp4y63FxsLXL4slr7TFtkqzLhx4mdMjKhiT4W7cwcIChIFxJo0AWrUAHr3Fut1JySYfkUCMj+XL4sk/vJloF494LffxLQhJXXvLn7+8YeYvlTeKZbIZ2RkQKPRwN3dXa/d3d0daWlpBve5fPkyNm7cCI1Gg23btmHmzJlYtGgR3nvvPd02/v7+WLNmDXbs2IEVK1YgKSkJAQEBuFtERZnIyEg4Ozvrbl5eXvKcJBEREZEBDRsC4eHi/sSJYuk3U3v4ML86/fjx8n4Jr1oV6NVL3DdW0bu8PCAyUtyfNEmsCFCUoCDRM5+Vlb88FhV07RrQoYOY52xvD9jZARkZwObNwOTJgL8/4OwMvPiiqK2wa5d5FW4k4zt/XiTxycni/7JffwXq1FE6KjEv//nnxf3t25WNxRQUL3ZXEnl5eahRowa++OIL+Pn5ISQkBNOnT0d0dLRum27duqFfv35o2bIlgoKCsG3bNty5cwfffvttoceNiIhAZmam7nbt2jVTnA4RERFVYDNmiLXaL18W8+VNbeVKIDERqF5dxCI37fD69etFQTq5bdkC/PUX4OQEjBnz9O2trPK3W7qUw8UNOXUKaNtWvK+ensDBg6J3/uBB4KOPgOBgoFo14N9/gT17gHnzxLxkFxdRKHHiRGDjRlFwjMqnM2fEnPiUFDEXfu9esSKHuahIw+utn76Jcbi6ukKtViM9PV2vPT09HR6FlDn09PREpUqVoFardW1NmjRBWloacnNzYWNjU2AfFxcXNGzYEBeLqGxia2sL28ImVRGRWcnLy0Nubq7SYRDJ7snPNyr/HB1FcjR4sKhgP2QIYKpBgXfuiN5UAJg7VyRicgsMFMWvUlKAH38EXntNvmNLUn7V/7FjRQ9xcQwbJi5aJCYC8fEiRhJ++UUMn8/KEgna9u1i3jMgkvu2bUUdgrw8MW9+3z5g/35xu3JFVAo/dgxYskTsU7++6Nnv0EHUXmjQQEwrIct18qT4N3PzJtCiBbB7t5h2YU5eeQWYM0csNZmTU3jdjPJAsUTexsYGfn5+iI+PR6//jb3Ky8tDfHw8xmpLiz6hffv2WL9+PfLy8mD1v5Kq58+fh6enp8EkHgDu3buHS5cuYUhhZUyJyGLk5uYiKSkJeRVlgVCqcFxcXODh4QEVv+1WGAMHAtHRIhl65x1gwwbTvO7774vh0o0bA6NGGec11GqxhntkpBheL2civ3u3mAdrby96gYvL2RkYOlQUvFu6lIm81vr14iLHw4diyPTmzWJ6hCFWViLRb9oU+M9/RNv16/lJ/f79IuG7eFHc1qwR27i5iaQ+LEz07JNlOXYM6NIFuH0beO45kShXr650VAU9+6wYTZKaKubtd+midETGo5Ik5QYWxcbGYujQofj888/Rpk0bREVF4dtvv8XZs2fh7u6O0NBQ1KpVC5H/mwB17do1NGvWDEOHDsW4ceNw4cIFvPHGGxg/fjymT58OAJg8eTKCg4NRp04d/P3335g9ezaOHz+OM2fOwM3NrVhxZWVlwdnZGZmZmXBycjLa+RNR8UmShOTkZDx8+BA1a9bUXcwjKg8kScL9+/dx48aN/2/vzuOiqvo/gH8GZJVNRRE3EMEd0HBJTcGlcCNITTQTDJcnU5/ckswQzV+pj0ummVopaD3uqS2Yigo+ilqmYi5Eaqhp7imKgMDM+f1xmpGRXQZm4fN+veYFM3PuvefcO8Phe88GJycnuLq6FkjDukm3DOl8JifLbskqleym6u9fsce7eFEGYepZydUTRFWE338HmjWTwd/Vq/IfbF0ICJDjct9++8lyfqX1229yAjeFQp6Lxo11kydjJITsFfLuu/L54MFyOT9r6/Lt9/594MiRJ4H9Tz9pD68YPFjeSDG01lwq3M8/yzkm7t8HOnQAdu+umF48ujJqFLB6tZz7Q91DxFiUqW4SerZs2TLRqFEjYWlpKTp06CCOHj2qec/f31+Eh4drpT98+LDo2LGjsLKyEh4eHuLDDz8UeXl5mvdDQ0OFq6ursLS0FPXr1xehoaHiwoULZcpTenq6ACDS09PLVTYi0p2cnBxx7tw5cf/+fX1nhajC3LlzR5w7d06rXlNj3aRbhnY+33xTCEAIb28hcnMr9liDBsljvfiiECpVxR5LCCE6d5bHmz9fN/s7dEjuz8JCiD//fLZ9vPii3MfUqbrJkzHKyxNi3Dh5HgAhJk0SQqmsmGNlZwuRlCTE5MlCmJvL4zk7C7FhQ+V8BunZHTokhL29vGZdughhIH8yi7V9u8yvh4fxfb7KUjfptUXeUBnSXXoikrKzs5GWlgZ3d3fY2NjoOztEFSIrKwuXLl1C48aNYf1UkxjrJt0ytPN5966c/fnvv2VLZRGjDMvt4EHZddrMTPYE8PaumOPk9+WXcmm45s3lRFnlHTnSrx+wc6dsdfvii2fbx/ffAy+/LLuPX71a8oz3piYrCxg2DNi+XV6PRYvkzP+V4cQJ2b3+11/l8+Bg4LPP5MSPZFgSE+WY80ePgO7d5QSTdnb6zlXJMjJkt/+cHDkfRvPm+s5R6ZWlbmLfVCIyKhw7TKaMn++qq1YtQL2ablSUHL+uayrVkyXvRo2qnCAekN2obWxkl/affy7fvpKTZRBvZgZERj77fvr2lV3q790D/vvf8uXJ2Ny5A/TsKYN4Kytg06bKC+IBOb762DE5yaKFBfDtt0CrVnIsPZsXDcfevfJ78uiRHGf+ww/GEcQDMp8BAfJ3U569noE8ERERkQEYMwbw9ZXjUP+Z+ken1q+XE8TZ2cllwyqLgwMwcKD8vbxryn/0kfw5ZIicFf1ZmZs/6fWwdGnVCSD/+APo0kWOX3dykmvAv/pq5efD0hKYORM4fhxo105+5t94A+jTR65NTvq1c6dsic/Kkj1gvvvO+Hqt9O8vfzKQJyIyEUql7Cq2YYP8qVTqO0dl5+7ujiVlmN0pMTERCoUC9+/fr7A8EVH5mZvLbvWA7DK+Y4fsFnr1KpCeXr6/V5mZwPTp8vf33gNcXMqd3TJRrym/caMMDp5Faqpcoxx4UpbyiIiQwcmZM3LiPFN3/LhcQu733+WycklJclk4ffL2ljcV5s+XvQN275at8ytXyh4kVPl27ABCQuTkhCEhwLZt5Z/8UB/U68kfOiRvFJkivS0/R0RU2bZtkzMcX7365LUGDeSMpgMG6P54JXWTjo6OxqxZs8q832PHjqF69eqlTt+5c2dcv34djqVdaJmI9KZrV7kk3fr1ck3vp9naAvb2slXd3r70j/h4+bfPza1yu1GrBQTIY1++LAOFoUPLvo9582TLeXAw0Lp1+fPk5AQMHw6sWiVvoKi74pqiH3+ULe+PHsleHzt3Gs6Y9GrV5NKLwcHy5srhw8DYsbLL/5dfAk2a6DuHVceWLfLvT16eHBLz9ddy+IMx8vCQq1OkpMgbRKGh+s6R7jGQJ6IqYds2uYbx090nr12Tr2/dqvtg/vr165rfN23ahJkzZyI1NVXzml2+wWZCCCiVSlSrVvKf5dIupalmaWmJunXrlmkbU5GTkwNLS0t9Z4OoTBYulEH3pUty0qaHD+X63oBsWc/MBG7efLZ9z5unn9Y1MzO5fvsHH8ju9WUN5C9flkEFIHsU6Mr48TKQ37FDdulu1Eh3+zYUq1fL9d6VSqBXL+Cbb+RwB0PTrJlc93v5ctnjIjER8PGRwynGj5c9Vqji/Pe/QFiY7Anx+uvye1qKf0kMWv/+MpCPizPNQJ5d64nI5CmVsiW+sDGQ6tcmTtR9N/u6detqHo6OjlAoFJrnv/32G+zt7fHjjz/Cz88PVlZWOHToEC5evIjg4GC4uLjAzs4O7du3x969e7X2+3TXeoVCgS+//BKvvPIKbG1t4eXlhe+++07z/tNd62NjY+Hk5ITdu3ejRYsWsLOzQ+/evbVuPOTl5eHf//43nJycUKtWLURGRiI8PBwhISFFlvfu3bsYOnQo6tevD1tbW3h7e2PDhg1aaVQqFf7zn//A09MTVlZWaNSoET788EPN+1evXsXQoUNRs2ZNVK9eHe3atcNPP/0EABgxYkSB40+cOBEB+ZrRAgICMH78eEycOBHOzs4IDAwEACxevBje3t6oXr06GjZsiLfeegsZGRla+0pKSkJAQABsbW1Ro0YNBAYG4t69e1i3bh1q1aqFx/kXQQYQEhKC4cOHF3k+iJ6Vq6vs6n35spzNPicHyM4Gbt+WY5xPnZLdRX/8Edi8WQZqS5YAc+bIls2xY+U/4sHBQI8eQPv2ctbmiAj9/jMbHi5/7t0L/Pln2bZdsEC2EvbqJdex1pXWreVs3CoVsGKF7vZrCIQAZs2SExsqlTJIi4szzCBezdxcrv19+rS8LpmZsn7u1k1OlkgVIyZG9k5RqeQwmNhY4w/igSfd63fuNM6hlCVhIE9EJu/gQe3u9E8TQv5TefBg5eVJ7d1338W8efOQkpICHx8fZGRkoG/fvti3bx9OnjyJ3r17IygoCFdKmP1n9uzZGDx4MH799Vf07dsXw4YNw99//11k+szMTCxcuBBfffUV/ve//+HKlSuYOnWq5v358+fjv//9L2JiYpCUlIQHDx5gx44dxeYhOzsbfn5+iIuLw5kzZzBmzBgMHz4cP+ebpnr69OmYN28eoqKicO7cOaxfvx4u/wzWzcjIgL+/P65du4bvvvsOp06dwrRp06Aq40DJtWvXwtLSEklJSVi5ciUAwMzMDEuXLsXZs2exdu1a7N+/H9OmTdNsk5ycjJ49e6Jly5Y4cuQIDh06hKCgICiVSrz66qtQKpVaN0du3bqFuLg4RERElClvRM/KygpwdpYzrfv4yAnLeveW3aUjIuTNyvffl2ONP/sM+Oor2cq8b5+cKT4lRQb8+lwYwcMD8PeXf3PXrSv9djduyC7WgG5b49X+/W/584svnn38vqHJzZVL/s2eLZ+/954Mzoylg5KHh/zsrlolh4YcPgy0aSM/33l5+s6d6VCpgE8/lX9DhADefFN+10yl90PnznIIzd27wD9tAqalohe1N0bp6ekCgEhPT9d3VojoH1lZWeLcuXMiKyurzNuuXy+ErKKKf6xfXwEZ/0dMTIxwdHTUPE9ISBAAxI4dO0rctlWrVmLZsmWa525ubuLjjz/WPAcg3n//fc3zjIwMAUD8+OOPWse6d++eJi8AxIULFzTbLF++XLi4uGieu7i4iAULFmie5+XliUaNGong4ODSFlkIIUS/fv3ElClThBBCPHjwQFhZWYkvvvii0LSrVq0S9vb24u7du4W+Hx4eXuD4b7/9tvD399c89/f3F23bti0xX1u2bBG1atXSPB86dKjo0qVLkenHjh0r+vTpo3m+aNEi4eHhIVQqVYnHKoviPuesm3SL51M/YmPl31tPTyFK+/WZNk1u06lT6bcpi7w8Idzc5DFWr9b9/ivbw4dC9Okjy2NmJsSKFfrOUflcufKkPIAQfn5C/PqrvnNl3B48EOKTT+T3UH1e3367Yr5f+hYaKsv33nv6zknplKVuYos8EZk8V1fdptOldu3aaT3PyMjA1KlT0aJFCzg5OcHOzg4pKSkltsj7+Phofq9evTocHBxw69atItPb2tqiSb4ZhFxdXTXp09PTcfPmTXTI13/V3Nwcfn5+xeZBqVRizpw58Pb2Rs2aNWFnZ4fdu3dr8p6SkoLHjx+jZ8+ehW6fnJyMtm3bombNmsUepySF5XPv3r3o2bMn6tevD3t7ewwfPhx3795FZmam5thF5QsARo8ejT179uDatWsA5PCEESNGcN13ojIaOBCoXh24cEHOml6Sv/+WPQwAuSRfRXzlzM2Bt96Svy9bVnlL0V26JCd0++EHICFBrq1+7pwcq3/3rpw1vKx5uXlTTtr344+AjY1cK/7NNysi95WnYUM5JGDtWtm6evw44Ocnexvk5Og7d8bljz/kZJcNGshePBcuyHM6dy7w8cf67bFTUUx5GToTGP1ARFS8rl1lpXXtWuH/FCkU8n19LMPz9OzzU6dORXx8PBYuXAhPT0/Y2Nhg0KBByCnhvxWLp6aVVSgUxXZJLyy9KOd/rwsWLMAnn3yCJUuWaMajT5w4UZN3GxubYrcv6X0zM7MCecxVzwCWz9Pn9NKlS+jfvz/Gjh2LDz/8EDVr1sShQ4cwcuRI5OTkwNbWtsRjt23bFr6+vli3bh1eeuklnD17FnFxccVuQ0QF2dnJ2bBjYuTjhReKT//pp3LCP19foG/fisvXyJFAdDSQnCxvMJSUr/L6/ns5X0FJXfnNzeU5q15d/sz/e2E/Y2KAtDQ5DOOHH4COHSu2HJVFoZBj/F98Ud502bFDjv//5hs5gWOrVrIeN5Uu4bokhJw48JNP5Hrw6mq0WTM5rCQsTH5+TFXv3nKyzV9/Nb0JLRnIE5HJMzeXFdigQfKfgfyxoPru85IlhvEPQFJSEkaMGIFX/ll3KiMjA5cuXarUPDg6OsLFxQXHjh1Dt27dAMjW9hMnTqBNmzZFbpeUlITg4GC8/vrrAOTEdr///jtatmwJAPDy8oKNjQ327duHUaNGFdjex8cHX375Jf7+++9CW+Vr166NM2fOaL2WnJxc4KbE044fPw6VSoVFixbBzEx2RNu8eXOBY+/btw+z1QNKCzFq1CgsWbIE165dQ69evdCwYcNij0tEhXvjDRlwbt4MLF0qA9DCZGTIv92AHONdka2FtWoBw4bJeQSWLavYQP7zz+WEhCqVnITQzk4uC5eR8eSn+t6tUgmkp8tHaTVpIlvkvbwqJv/65OoqV6HZsgUYN05Oiqee0KxaNRmkeXjIuSTUD/VzZ+fKb3EWQs5XoI+5CbKz5TKWn3wig1i1wEA5geBLL8kA19Q5OwPPPy/nWdi50/h7qOTHQJ6IqoQBA+QSc4WtI79kScWsI/8svLy8sG3bNgQFBUGhUCAqKqrMk73pwoQJEzB37lx4enqiefPmWLZsGe7du1dsV3IvLy9s3boVhw8fRo0aNbB48WLcvHlTE8hbW1sjMjIS06ZNg6WlJbp06YLbt2/j7NmzGDlyJIYOHYqPPvoIISEhmDt3LlxdXXHy5EnUq1cPnTp1Qo8ePbBgwQKsW7cOnTp1wtdff40zZ86gbdu2xZbF09MTubm5WLZsGYKCgrQmwVObPn06vL298dZbb+HNN9+EpaUlEhIS8Oqrr8LZ2RkA8Nprr2Hq1Kn44osvsK4sM3URkZYXXpDB5sWLskU1LKzwdKtWya71TZvKLvkVbcIEGch/843swVW/vm73r55F/oMP5POICGDlysLX6c7NlUH90wF+ST8dHYF33gHq1NFt3g2JQiF7dXTvLm/wqFd4yMmRXcf/+KPw7apXLzrIb9y46BtKQsieE/fuycfff5ftd6VStn4//zzQqZP82bp1xTUe/PWXXIFh1Sq50gUA2NrKVSMmTJBrq1c1/fvLQP6HHxjIExEZpQED5HJMBw8C16/LO/tduxpGS7za4sWLERERgc6dO8PZ2RmRkZF48OBBpecjMjISN27cQFhYGMzNzTFmzBgEBgbCvJiT9f777+OPP/5AYGAgbG1tMWbMGISEhCA9X1NSVFQUqlWrhpkzZ+Kvv/6Cq6sr3vynVrW0tMSePXswZcoU9O3bF3l5eWjZsiWWL18OAAgMDERUVBSmTZuG7OxsREREICwsDKdPny62LL6+vli8eDHmz5+P6dOno1u3bpg7dy7C8kUPTZs2xZ49e/Dee++hQ4cOsLGxQceOHTE032LXjo6OGDhwIOLi4opdho+IiqdQACNGAFFRsmW+sEA+OxtYuFD+/u67lfN32tdXLnP2v//JAHvOHN3tOy9PBhCrV8vnUVFyjHdR90YtLOTYZScn3eXB1NSuLVcaAGSw/NdfcliB+vHHH09+v3ZN3uw4fVo+ClOnzpOW+/v3tYPxp1YfLbPUVPlYu1Y+t7OTyyjmD+7/uWf8zI4dk63vmzfLG0GA7KEwfrxcgrBGjfLt35j17y9v+uzbJ5c0tLXVd450QyHKOyjSBD148ACOjo5IT0+HgyEvtklUhWRnZyMtLQ2NGzeGtbW1vrNT5ahUKrRo0QKDBw/GHF3+d2tkevbsiVatWmHp0qUVsv/iPuesm3SL51O/rlwB3N1la+cff8gAKr8VK+RY6IYN5YRcldU1eetWuaRf7doyj7qobh49ki3IO3fKrswrVgBjxpR/v1R62dmy1b6wID8tTQbrJTE3l8FwzZraP4v6Xf3TzAw4cQI4cgQ4elQug/bwYcH9e3o+Ceo7dQK8vUteyz0vTw41+OQT2eKs9sILsgdiSIhprAdfXkIAbm5yqeEffngyHMMQlaVu4qUlIqICLl++jD179sDf3x+PHz/Gp59+irS0NLz22mv6zppe3Lt3D4mJiUhMTMRn6im0ieiZNWoE9OwJ7N0rWylnzXryXm4u8J//yN+nTavc8cUhIXLI1dWrsmWzqG7/pXX7tgwajh2Ts8hv3Ai8/LJOskplYG0tu7c3a1b4+/fvawf1Tk4Fg3I7u2cfY9+375PJGpVKuTrB0aNPgvuUFHnD6sIF4KuvZDpbW6B9e+3gXj1k4u+/ZW+ETz99MlzQwgIYMkQG8CUsMlPlKBSyVX7FCsMP5MuCgTwRERVgZmaG2NhYTJ06FUIItG7dGnv37kWLqji4DnLW+nv37mH+/PloVtR/gkRUJm+8IQP52Fhg5swnE29t2CCXZqtTR84mX5mqVZMT0c2YISe9Gz782YO3ixfljNkXLsjJ9L7/XgZjZHicnIC2beWjopmby9Z2b29g9Gj52r17sqVeHdz/9JOc4PDAAflQa9wYaNkS2L//yYoHderIYRtjxwJ161Z8/o2VOpCPi5Mt9Kaw1B671heC3e2IDA+71lNVwK71lYfnU/8yM+VcJQ8eyMCke3c5k3urVsBvv8llxSIjKz9ft2/LLv2PH8ug6vnny76PX36RrX63bskhBLt2Fd0aTPQ0lUp+B9SB/ZEjshU/f9TWpo2cfX7IEMDKSl85NR5ZWfKGWlYWcOoU4OOj7xwVrix1UxVYdICIiIiIDI2trQxCADnpHQBs3y4DGCcn2cKoD7VrA+p5LpctK/v2u3YBAQEyiG/TRo5dZhBPZWFmJlveIyJkF/ozZ2Sr/Z49wKJFspX+xAk5Ez2D+NKxsZHDeQDZvd4UMJAnIiIiIr0YMUL+3LpVtsx/9JF8PmECoM+OEhMmyJ9btshVTkpr7VogKEhOcNerlwy4XF0rJo9UtTg6Ai++CEyeLFdXMIWu4ZVNPTY+Lk6/+dAVBvJEREREpBfPPy9bq7Oy5HjhEyfket5vv63ffD33HNC5s5x4b9WqktMLIW9CjBghZxJ//XUZLHDUBpHhUAfyR44Ad+7oNy+6wECeiIiIiPRCoZCT3gFylngA+Ne/5FhWfVO3yq9aBeTkFJ1OqQTGjZMT5AFyXP/atZU72z4RlaxhQ8DXV954i4qSE2vGxwMnT8ql6dQTCBoLzlpPRERERHozfDjw3ntygi9LS2DKFH3nSBo4UHaLv35ddv0vbPXNrCz5+o4d8qbEJ588uQFARIYnKEhOdrdypXw8zdYWcHYu+lG7tvbzWrXk0n/6wECeiIiIiPSmXj25TNvOnbJ1vl49fedIsrCQE+7NnCknvXs6kL97V64Jf/iwnHDs66+BQYP0k1ciKp1Jk+QNuCtXZPf6/I/cXLmaxpUr8lFajo5Aixayy35lYiBfgZRK4OBBeSfX1RXo2lWuHUlEVBYBAQFo06YNlixZAgBwd3fHxIkTMXHixCK3USgU2L59O0JCQsp1bF3th4ioOJ99Bnz1FfDvf+s7J9rGjAH+7//kMmC//AK0aydfv3xZ3nxQz7D/7bdyAjIiMmw1awILFxZ8XQjg4cOCwb36cft2wdfu3pXbpafLbSsbA/kKsm2bnKjl6tUnrzVoILtcDRigv3wRUeUJCgpCbm4udu3aVeC9gwcPolu3bjh16hR8yriY6bFjx1C9enVdZRMAMGvWLOzYsQPJyclar1+/fh01atTQ6bGIiJ7m5ga8/76+c1GQiwsweLBsbV+2TI59T04G+vaVDTUNGsjl5lq10ndOiag8FAo5OaWDA+DhUbptlErg/n0Z1Bc3j0ZF4WR3FWDbNtm1Kn8QDwDXrsnXt23TT76IqHKNHDkS8fHxuPr0HwMAMTExaNeuXZmDeACoXbs2bG1tdZHFEtWtWxdWVXCR2hx91MhEZJDUY943bpSPbt1kEN+6texKyyCeqGoyN5dj5Js1A7y9K//4DOR1TKmULfFCFHxP/drEiTIdET07IeQ6vfp4FPb9Lkz//v1Ru3ZtxMbGar2ekZGBLVu2YOTIkbh79y6GDh2K+vXrw9bWFt7e3tiwYUOx+3V3d9d0sweA8+fPo1u3brC2tkbLli0RHx9fYJvIyEg0bdoUtra28PDwQFRUFHJzcwEAsbGxmD17Nk6dOgWFQgGFQqHJs0KhwI4dOzT7OX36NHr06AEbGxvUqlULY8aMQUZGhub9ESNGICQkBAsXLoSrqytq1aqFcePGaY5VmIsXLyI4OBguLi6ws7ND+/btsXfvXq00jx8/RmRkJBo2bAgrKyt4enpi9erVmvfPnj2L/v37w8HBAfb29ujatSsuXrwIQA5NeHoYQkhICEaoF7D+55zOmTMHYWFhcHBwwJgxY0o8b2rff/892rdvD2trazg7O+OVV14BAHzwwQdo3bp1gfK2adMGUVFRRZ4PIjIsHTrIR04OMHSo7EIbECCHTzZooO/cEVFVxa71OnbwYMGW+PyEkMsbHDwoKwEiejaZmYCdnX6OnZEh1zkuSbVq1RAWFobY2FjMmDEDCoUCALBlyxYolUoMHToUGRkZ8PPzQ2RkJBwcHBAXF4fhw4ejSZMm6NChQ4nHUKlUGDBgAFxcXPDTTz8hPT290LHz9vb2iI2NRb169XD69GmMHj0a9vb2mDZtGkJDQ3HmzBns2rVLE0A7OjoW2MejR48QGBiITp064dixY7h16xZGjRqF8ePHa92sSEhIgKurKxISEnDhwgWEhoaiTZs2GD16dBHnMwN9+/bFhx9+CCsrK6xbtw5BQUFITU1Fo0aNAABhYWE4cuQIli5dCl9fX6SlpeHOP4vAXrt2Dd26dUNAQAD2798PBwcHJCUlIS8vr8Tzl9/ChQsxc+ZMREdHl+q8AUBcXBxeeeUVzJgxA+vWrUNOTg527twJAIiIiMDs2bNx7NgxtG/fHgBw8uRJ/Prrr9jGrllERmXCBDm7PiC72q9bJye4IyLSG0EFpKenCwAiPT29zNuuXy+EDNeLf6xfXwEZJzJhWVlZ4ty5cyIrK0sIIURGRum+axXxyMgofb5TUlIEAJGQkKB5rWvXruL1118vcpt+/fqJKVOmaJ77+/uLt99+W/Pczc1NfPzxx0IIIXbv3i2qVasmrl27pnn/xx9/FADE9u3bizzGggULhJ+fn+Z5dHS08PX1LZAu/34+//xzUaNGDZGR7wTExcUJMzMzcePGDSGEEOHh4cLNzU3k5eVp0rz66qsiNDS0yLwUplWrVmLZsmVCCCFSU1MFABEfH19o2unTp4vGjRuLnJycQt9/+vwJIURwcLAIDw/XPHdzcxMhISEl5uvp89apUycxbNiwItP36dNHjB07VvN8woQJIiAgoMj0T3/O8ytP3UQF8XxSWeTkCDF6tBBz5gihVOo7N0RkqspSN7FFXsdcXXWbjogKZ2srW8b1dezSat68OTp37ow1a9YgICAAFy5cwMGDB/HBBx8AAJRKJT766CNs3rwZ165dQ05ODh4/flzqMfApKSlo2LAh6uVbr6lTp04F0m3atAlLly7FxYsXkZGRgby8PDg4OJS+IP8cy9fXV2uivS5dukClUiE1NRUuLi4AgFatWsE83xIdrq6uOH36dJH7zcjIwKxZsxAXF4fr168jLy8PWVlZuPLP2i/JyckwNzeHv79/odsnJyeja9eusCjnQq7t1NNR51PSeUtOTi6ypwEAjB49GhEREVi8eDHMzMywfv16fPzxx+XKJxFVPgsL4PPP9Z0LIqInGMjrWNeucrzUtWuFj6NVKOT7XbtWft6ITIlCUbru7YZg5MiRmDBhApYvX46YmBg0adJEE5QuWLAAn3zyCZYsWQJvb29Ur14dEydO1Olka0eOHMGwYcMwe/ZsBAYGwtHRERs3bsSiRYt0doz8ng6oFQoFVCpVkemnTp2K+Ph4LFy4EJ6enrCxscGgQYM058DGxqbY45X0vpmZGcRTf5ALG7P/9EoApTlvJR07KCgIVlZW2L59OywtLZGbm4tBXGiaiIiIyomT3emYublcYg6QgUZ+6udLlnA9eaKqZPDgwZrW2HXr1iEiIkIzXj4pKQnBwcF4/fXX4evrCw8PD/z++++l3neLFi3w559/4vr165rXjh49qpXm8OHDcHNzw4wZM9CuXTt4eXnh8uXLWmksLS2hLGEWzhYtWuDUqVN49OiR5rWkpCSYmZmhWbNmpc7z05KSkjBixAi88sor8Pb2Rt26dXHp0iXN+97e3lCpVDhw4ECh2/v4+ODgwYNFTqhXu3ZtrfOjVCpx5syZEvNVmvPm4+ODffv2FbmPatWqITw8HDExMYiJicGQIUNKDP6JiIiISsJAvgIMGABs3QrUr6/9eoMG8nWuI09UtdjZ2SE0NBTTp0/H9evXtWZL9/LyQnx8PA4fPoyUlBT861//ws2bN0u97169eqFp06YIDw/HqVOncPDgQcyYMUMrjZeXF65cuYKNGzfi4sWLWLp0KbZv366Vxt3dHWlpaUhOTsadO3fw+PHjAscaNmwYrK2tER4ejjNnziAhIQETJkzA8OHDNd3qn4WXlxe2bduG5ORknDp1Cq+99ppWC767uzvCw8MRERGBHTt2IC0tDYmJidi8eTMAYPz48Xjw4AGGDBmCX375BefPn8dXX32F1NRUAECPHj0QFxeHuLg4/Pbbbxg7dizu379fqnyVdN6io6OxYcMGREdHIyUlBadPn8b8+fO10owaNQr79+/Hrl27EBER8czniYiIiEiNgXwFGTAAuHQJSEgA1q+XP9PSGMQTVVUjR47EvXv3EBgYqDWe/f3338dzzz2HwMBABAQEoG7duggJCSn1fs3MzLB9+3ZkZWWhQ4cOGDVqFD788EOtNC+//DImTZqE8ePHo02bNjh8+HCB5c8GDhyI3r17o3v37qhdu3ahS+DZ2tpi9+7d+Pvvv9G+fXsMGjQIPXv2xKefflq2k/GUxYsXo0aNGujcuTOCgoIQGBiI5557TivNihUrMGjQILz11lto3rw5Ro8erekZUKtWLezfvx8ZGRnw9/eHn58fvvjiC00X/4iICISHhyMsLAz+/v7w8PBA9+7dS8xXac5bQEAAtmzZgu+++w5t2rRBjx498PPPP2ul8fLyQufOndG8eXN07NixPKeKiIiICACgEE8PHCQ8ePAAjo6OSE9PL/NkUERUMbKzs5GWlobGjRvD2tpa39khKjUhBLy8vPDWW29h8uTJxaYt7nPOukm3eD6JiMjQlKVu4mR3REREFeT27dvYuHEjbty4gTfeeEPf2SEiIiITwUCeiIiogtSpUwfOzs74/PPPUaNGDX1nh4iIiEwEx8gTERFVECEEbt++jddee03fWTF4y5cvh7u7O6ytrdGxY8cCcw3kd/bsWQwcOBDu7u5QKBRYsmRJ5WWUiIjIADCQJyIiIr3atGkTJk+ejOjoaJw4cQK+vr4IDAzErVu3Ck2fmZkJDw8PzJs3D3Xr1q3k3BIREekfA3kiMiqcn5NMWVX9fC9evBijR4/GG2+8gZYtW2LlypWwtbXFmjVrCk3fvn17LFiwAEOGDIGVlVUl55aIiEj/GMgTkVEwNzcHAOTk5Og5J0QVJzMzEwA0S+dVBTk5OTh+/Dh69eqlec3MzAy9evXCkSNHdHacx48f48GDB1oPIiIiY8XJ7ojIKFSrVg22tra4ffs2LCwsYGbG+5BkOoQQyMzMxK1bt+Dk5KS5cVUV3LlzB0qlEi4uLlqvu7i44LffftPZcebOnYvZs2frbH9ERET6xECeiIyCQqGAq6sr0tLScPnyZX1nh6hCODk5ccx3BZk+fTomT56sef7gwQM0bNhQjzkiIiJ6dgzkichoWFpawsvLi93rySRZWFhUqZZ4NWdnZ5ibm+PmzZtar9+8eVOnNzWsrKw4np6IiEwGA3kiMipmZmawtrbWdzaISEcsLS3h5+eHffv2ISQkBACgUqmwb98+jB8/Xr+ZIyIiMlAM5ImIiEivJk+ejPDwcLRr1w4dOnTAkiVL8OjRI7zxxhsAgLCwMNSvXx9z584FICfIO3funOb3a9euITk5GXZ2dvD09NRbOYiIiCoLA3kiIiLSq9DQUNy+fRszZ87EjRs30KZNG+zatUszAd6VK1e0Jrj866+/0LZtW83zhQsXYuHChfD390diYmJlZ5+IiKjSKURVXbS2GA8ePICjoyPS09Ph4OCg7+wQERGxbtIxnk8iIjI0Zamb2CJfCPW9Da4xS0REhkJdJ/H+u26wriciIkNTlrqegXwhHj58CABcloaIiAzOw4cP4ejoqO9sGD3W9UREZKhKU9eza30hVCoV/vrrL9jb20OhUJRrX+p1av/880+j77pnKmUxlXIALIshMpVyAKZTFlMphxACDx8+RL169bTGi9Oz0WVdD5jO58xUygGYTllMpRyA6ZTFVMoBmE5ZTKUcZanr2SJfCDMzMzRo0ECn+3RwcDDqD1V+plIWUykHwLIYIlMpB2A6ZTGFcrAlXncqoq4HTONzBphOOQDTKYuplAMwnbKYSjkA0ymLKZSjtHU9b+kTERERERERGREG8kRERERERERGhIF8BbOyskJ0dDSsrKz0nZVyM5WymEo5AJbFEJlKOQDTKYuplIMMm6l8zkylHIDplMVUygGYTllMpRyA6ZTFVMpRFpzsjoiIiIiIiMiIsEWeiIiIiIiIyIgwkCciIiIiIiIyIgzkiYiIiIiIiIwIA3kiIiIiIiIiI8JAXgeWL18Od3d3WFtbo2PHjvj555+LTb9lyxY0b94c1tbW8Pb2xs6dOyspp0WbO3cu2rdvD3t7e9SpUwchISFITU0tdpvY2FgoFAqth7W1dSXluHCzZs0qkKfmzZsXu40hXg8AcHd3L1AWhUKBcePGFZrekK7H//73PwQFBaFevXpQKBTYsWOH1vtCCMycOROurq6wsbFBr169cP78+RL3W9bvWnkVV47c3FxERkbC29sb1atXR7169RAWFoa//vqr2H0+y2dUF0q6JiNGjCiQr969e5e4X0O6JgAK/c4oFAosWLCgyH3q65qQcWFdr/+6JT9Tqe9Z1xdU2fUKYDr1vanU9QDr+9JgIF9OmzZtwuTJkxEdHY0TJ07A19cXgYGBuHXrVqHpDx8+jKFDh2LkyJE4efIkQkJCEBISgjNnzlRyzrUdOHAA48aNw9GjRxEfH4/c3Fy89NJLePToUbHbOTg44Pr165rH5cuXKynHRWvVqpVWng4dOlRkWkO9HgBw7NgxrXLEx8cDAF599dUitzGU6/Ho0SP4+vpi+fLlhb7/n//8B0uXLsXKlSvx008/oXr16ggMDER2dnaR+yzrd00XiitHZmYmTpw4gaioKJw4cQLbtm1DamoqXn755RL3W5bPqK6UdE0AoHfv3lr52rBhQ7H7NLRrAkAr/9evX8eaNWugUCgwcODAYverj2tCxoN1vWHULU8zhfqedb02fdQrgOnU96ZS1wOs70tFULl06NBBjBs3TvNcqVSKevXqiblz5xaafvDgwaJfv35ar3Xs2FH861//qtB8ltWtW7cEAHHgwIEi08TExAhHR8fKy1QpREdHC19f31KnN5brIYQQb7/9tmjSpIlQqVSFvm+I10MIIQCI7du3a56rVCpRt25dsWDBAs1r9+/fF1ZWVmLDhg1F7qes3zVde7ochfn5558FAHH58uUi05T1M1oRCitLeHi4CA4OLtN+jOGaBAcHix49ehSbxhCuCRk21vWOlZepUjLV+p51vX7rFSFMp743lbpeCNb3RWGLfDnk5OTg+PHj6NWrl+Y1MzMz9OrVC0eOHCl0myNHjmilB4DAwMAi0+tLeno6AKBmzZrFpsvIyICbmxsaNmyI4OBgnD17tjKyV6zz58+jXr168PDwwLBhw3DlypUi0xrL9cjJycHXX3+NiIgIKBSKItMZ4vV4WlpaGm7cuKF13h0dHdGxY8ciz/uzfNf0IT09HQqFAk5OTsWmK8tntDIlJiaiTp06aNasGcaOHYu7d+8WmdYYrsnNmzcRFxeHkSNHlpjWUK8J6R/resOtW0ytvmddb/j1ipox1/emVtcDVbe+ZyBfDnfu3IFSqYSLi4vW6y4uLrhx40ah29y4caNM6fVBpVJh4sSJ6NKlC1q3bl1kumbNmmHNmjX49ttv8fXXX0OlUqFz5864evVqJeZWW8eOHREbG4tdu3ZhxYoVSEtLQ9euXfHw4cNC0xvD9QCAHTt24P79+xgxYkSRaQzxehRGfW7Lct6f5btW2bKzsxEZGYmhQ4fCwcGhyHRl/YxWlt69e2PdunXYt28f5s+fjwMHDqBPnz5QKpWFpjeGa7J27VrY29tjwIABxaYz1GtChoF1vWHWLaZY37OuN/x6BTDu+t4U63qg6tb31fSdATI848aNw5kzZ0ocM9KpUyd06tRJ87xz585o0aIFVq1ahTlz5lR0NgvVp08fze8+Pj7o2LEj3NzcsHnz5lLdpTNUq1evRp8+fVCvXr0i0xji9agqcnNzMXjwYAghsGLFimLTGupndMiQIZrfvb294ePjgyZNmiAxMRE9e/bUW77KY82aNRg2bFiJE0EZ6jUhqkjGXNcDpvm9ZV1v+Iy9vjfFuh6ouvU9W+TLwdnZGebm5rh586bW6zdv3kTdunUL3aZu3bplSl/Zxo8fjx9++AEJCQlo0KBBmba1sLBA27ZtceHChQrKXdk5OTmhadOmRebJ0K8HAFy+fBl79+7FqFGjyrSdIV4PAJpzW5bz/izftcqirtQvX76M+Pj4Yu/OF6akz6i+eHh4wNnZuch8GfI1AYCDBw8iNTW1zN8bwHCvCekH63pthlq3GHt9z7re8OsVU6zvjb2uB6p2fc9AvhwsLS3h5+eHffv2aV5TqVTYt2+f1t3S/Dp16qSVHgDi4+OLTF9ZhBAYP348tm/fjv3796Nx48Zl3odSqcTp06fh6upaATl8NhkZGbh48WKReTLU65FfTEwM6tSpg379+pVpO0O8HgDQuHFj1K1bV+u8P3jwAD/99FOR5/1ZvmuVQV2pnz9/Hnv37kWtWrXKvI+SPqP6cvXqVdy9e7fIfBnqNVFbvXo1/Pz84OvrW+ZtDfWakH6wrtdmqHWLsdf3rOsNu14x1fre2Ot6oIrX9/qda8/4bdy4UVhZWYnY2Fhx7tw5MWbMGOHk5CRu3LghhBBi+PDh4t1339WkT0pKEtWqVRMLFy4UKSkpIjo6WlhYWIjTp0/rqwhCCCHGjh0rHB0dRWJiorh+/brmkZmZqUnzdFlmz54tdu/eLS5evCiOHz8uhgwZIqytrcXZs2f1UQQhhBBTpkwRiYmJIi0tTSQlJYlevXoJZ2dncevWLSGE8VwPNaVSKRo1aiQiIyMLvGfI1+Phw4fi5MmT4uTJkwKAWLx4sTh58qRmdtd58+YJJycn8e2334pff/1VBAcHi8aNG4usrCzNPnr06CGWLVumeV7Sd62yy5GTkyNefvll0aBBA5GcnKz1vXn8+HGR5SjpM6qPsjx8+FBMnTpVHDlyRKSlpYm9e/eK5557Tnh5eYns7Owiy2Jo10QtPT1d2NraihUrVhS6D0O5JmQ8WNcbRt2SnynV96zr9VuvlFQWY6rvTaWuL6ksalW9vmcgrwPLli0TjRo1EpaWlqJDhw7i6NGjmvf8/f1FeHi4VvrNmzeLpk2bCktLS9GqVSsRFxdXyTkuCEChj5iYGE2ap8syceJETbldXFxE3759xYkTJyo/8/mEhoYKV1dXYWlpKerXry9CQ0PFhQsXNO8by/VQ2717twAgUlNTC7xnyNcjISGh0M+TOr8qlUpERUUJFxcXYWVlJXr27FmgjG5ubiI6OlrrteK+a5VdjrS0tCK/NwkJCUWWo6TPqD7KkpmZKV566SVRu3ZtYWFhIdzc3MTo0aMLVNKGfk3UVq1aJWxsbMT9+/cL3YehXBMyLqzr9V+35GdK9T3r+mit1yq7XimpLMZU35tKXV9SWdSqen2vEEKIZ23NJyIiIiIiIqLKxTHyREREREREREaEgTwRERERERGREWEgT0RERERERGREGMgTERERERERGREG8kRERERERERGhIE8ERERERERkRFhIE9ERERERERkRBjIExERERERERkRBvJEpHeJiYlQKBS4f/++vrNCREREFYT1PZHuMJAnIiIiIiIiMiIM5ImIiIiIiIiMCAN5IoJKpcLcuXPRuHFj2NjYwNfXF1u3bgXwpBtcXFwcfHx8YG1tjeeffx5nzpzR2sc333yDVq1awcrKCu7u7li0aJHW+48fP0ZkZCQaNmwIKysreHp6YvXq1Vppjh8/jnbt2sHW1hadO3dGamqq5r1Tp06he/fusLe3h4ODA/z8/PDLL79U0BkhIiIyPazviUwHA3kiwty5c7Fu3TqsXLkSZ8+exaRJk/D666/jwIEDmjTvvPMOFi1ahGPHjqF27doICgpCbm4uAFkhDx48GEOGDMHp06cxa9YsREVFITY2VrN9WFgYNmzYgKVLlyIlJQWrVq2CnZ2dVj5mzJiBRYsW4ZdffkG1atUQERGheW/YsGFo0KABjh07huPHj+Pdd9+FhYVFxZ4YIiIiE8L6nsiECCKq0rKzs4Wtra04fPiw1usjR44UQ4cOFQkJCQKA2Lhxo+a9u3fvChsbG7Fp0yYhhBCvvfaaePHFF7W2f+edd0TLli2FEEKkpqYKACI+Pr7QPKiPsXfvXs1rcXFxAoDIysoSQghhb28vYmNjy19gIiKiKoj1PZFpYYs8URV34cIFZGZm4sUXX4SdnZ3msW7dOly8eFGTrlOnTprfa9asiWbNmiElJQUAkJKSgi5dumjtt0uXLjh//jyUSiWSk5Nhbm4Of3//YvPi4+Oj+d3V1RUAcOvWLQDA5MmTMWrUKPTq1Qvz5s3TyhsREREVj/U9kWlhIE9UxWVkZAAA4uLikJycrHmcO3dOM26uvGxsbEqVLn/XOYVCAUCO5wOAWbNm4ezZs+jXrx/279+Pli1bYvv27TrJHxERkaljfU9kWhjIE1VxLVu2hJWVFa5cuQJPT0+tR8OGDTXpjh49qvn93r17+P3339GiRQsAQIsWLZCUlKS136SkJDRt2hTm5ubw9vaGSqXSGoP3LJo2bYpJkyZhz549GDBgAGJiYsq1PyIioqqC9T2Raamm7wwQkX7Z29tj6tSpmDRpElQqFV544QWkp6cjKSkJDg4OcHNzAwB88MEHqFWrFlxcXDBjxgw4OzsjJCQEADBlyhS0b98ec+bMQWhoKI4cOYJPP/0Un332GQDA3d0d4eHhiIiIwNKlS+Hr64vLly/j1q1bGDx4cIl5zMrKwjvvvINBgwahcePGuHr1Ko4dO4aBAwdW2HkhIiIyJazviUyMvgfpE5H+qVQqsWTJEtGsWTNhYWEhateuLQIDA8WBAwc0E9N8//33olWrVsLS0lJ06NBBnDp1SmsfW7duFS1bthQWFhaiUaNGYsGCBVrvZ2VliUmTJglXV1dhaWkpPD09xZo1a4QQTya/uXfvnib9yZMnBQCRlpYmHj9+LIYMGSIaNmwoLC0tRb169cT48eM1E+MQERFRyVjfE5kOhRBC6PNGAhEZtsTERHTv3h337t2Dk5OTvrNDREREFYD1PZFx4Rh5IiIiIiIiIiPCQJ6IiIiIiIjIiLBrPREREREREZERYYs8ERERERERkRFhIE9ERERERERkRBjIExERERERERkRBvJERERERERERoSBPBEREREREZERYSBPREREREREZEQYyBMREREREREZEQbyREREREREREbk/wFgrxqW+FVKJwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss_acc(history):\n",
    "    '''Plots the training and validation loss and accuracy from a history object'''\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "    ax[0].plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "    ax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    ax[0].set_title('Training and validation accuracy')\n",
    "    ax[0].set_xlabel('epochs')\n",
    "    ax[0].set_ylabel('accuracy')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    ax[1].plot(epochs, loss, 'bo', label='Training Loss')\n",
    "    ax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    ax[1].set_title('Training and validation loss')\n",
    "    ax[1].set_xlabel('epochs')\n",
    "    ax[1].set_ylabel('loss')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
